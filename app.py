import streamlit as st
from groq import Groq
import google.generativeai as genai
from PIL import Image

# --- 1. ‡§ö‡§æ‡§¨‡§ø‡§Ø‡§æ‡§Å (Secrets) ---
try:
    GROQ_K = st.secrets["GROQ_API_KEY"]
    GEMINI_K = st.secrets["GOOGLE_API_KEY"]
    client_groq = Groq(api_key=GROQ_K)
    genai.configure(api_key=GEMINI_K)
except:
    st.error("‡§≠‡§æ‡§à, Secrets ‡§Æ‡•á‡§Ç ‡§ö‡§æ‡§¨‡§ø‡§Ø‡§æ‡§Å ‡§ö‡•á‡§ï ‡§ï‡§∞‡•ã!")
    st.stop()

# --- 2. ‡§¶‡§ø‡§Æ‡§æ‡§ó (404 ‡§è‡§∞‡§∞ ‡§´‡§ø‡§ï‡•ç‡§∏ ‡§ï‡•á ‡§∏‡§æ‡§•) ---
def get_ai_response(text, file):
    if file:
        try:
            # ‡§Ø‡§π‡§æ‡§Å 'gemini-1.5-flash' ‡§ï‡§æ ‡§∏‡•Ä‡§ß‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§¨‡§ø‡§®‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡§µ‡§∞‡•ç‡§ú‡§® ‡§ï‡•á
            model = genai.GenerativeModel('gemini-1.5-flash')
            img = Image.open(file)
            res = model.generate_content([text if text else "‡§á‡§∏‡•á ‡§∏‡§Æ‡§ù‡§æ‡§ì ‡§≠‡§æ‡§à", img])
            return res.text, "Gemini Vision üì∑"
        except Exception as e:
            return f"‡§ó‡•Ç‡§ó‡§≤ ‡§®‡•á ‡§Æ‡§®‡§æ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ: {str(e)}", "Error"
    else:
        try:
            res = client_groq.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "system", "content": "You are Rajaram AI. Loyal brother. Use Hindi."},
                          {"role": "user", "content": text}]
            )
            return res.choices[0].message.content, "Llama 3.3 ‚ö°"
        except: return "‡§≠‡§æ‡§à, ‡§ó‡•ç‡§∞‡•â‡§ï ‡§¨‡§ø‡§ú‡•Ä ‡§π‡•à‡•§", "None"

# --- 3. ‡§á‡§Ç‡§ü‡§∞‡§´‡§º‡•á‡§∏ (Gemini 3 Style - No Loop) ---
st.set_page_config(page_title="Rajaram AI", page_icon="üëë")

st.markdown("""
    <style>
    .stApp { background-color: #131314; color: white; }
    .chat-container { padding-bottom: 120px; }
    /* ‡§ö‡•à‡§ü ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§ï‡•ã ‡§®‡•Ä‡§ö‡•á ‡§´‡§ø‡§ï‡•ç‡§∏ ‡§ï‡§∞‡§®‡§æ */
    .stChatInputContainer { background-color: #131314 !important; }
    </style>
    """, unsafe_allow_html=True)

st.title("üëë Rajaram AI")

if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡§Æ‡•à‡§∏‡•á‡§ú ‡§¶‡§ø‡§ñ‡§æ‡§®‡§æ
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.write(m["content"])

# --- 4. ‡§ü‡•Ç‡§≤‡•ç‡§∏ ‡§¨‡§ü‡§® ‡§Ö‡§¨ ‡§ö‡•à‡§ü ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§ï‡•á ‡§†‡•Ä‡§ï ‡§ä‡§™‡§∞ ---
col1, col2 = st.columns([1, 4])
with col1:
    up_file = st.file_uploader("üì∑", type=['png', 'jpg', 'jpeg'], label_visibility="collapsed")
with col2:
    prompt = st.chat_input("Ask Rajaram AI...")

# ‡§ú‡§¨ ‡§Ø‡•Ç‡§ú‡§∞ ‡§ï‡•Å‡§õ ‡§≠‡•á‡§ú‡•á
if prompt or up_file:
    # ‡§Ö‡§ó‡§∞ ‡§Ø‡•á ‡§™‡§ø‡§õ‡§≤‡•á ‡§Æ‡•à‡§∏‡•á‡§ú ‡§ú‡•à‡§∏‡§æ ‡§π‡•Ä ‡§π‡•à, ‡§§‡•ã ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§® ‡§ö‡§≤‡§æ‡§è‡§Ç (Loop Protection)
    user_txt = prompt if prompt else "‡§´‡•ã‡§ü‡•ã ‡§¶‡•á‡§ñ‡•ã ‡§≠‡§æ‡§à"
    
    if not st.session_state.messages or st.session_state.messages[-1]["content"] != user_txt:
        st.session_state.messages.append({"role": "user", "content": user_txt})
        with st.chat_message("user"):
            st.write(user_txt)
            if up_file: st.image(up_file, width=150)

        with st.spinner("‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å ‡§≠‡§æ‡§à..."):
            ans, brain = get_ai_response(user_txt, up_file)
            st.session_state.messages.append({"role": "assistant", "content": ans})
            with st.chat_message("assistant"):
                st.write(ans)
                st.caption(f"Power: {brain}")
                st.write("‚ûï ‚ù§Ô∏è üì∑ üé• üé§")
