# ==============================================================================
# PROJECT: RAJARAM AI - THE OMNIPOTENT CORE (VERSION 6.0)
# DEVELOPER: RAJARAM (BAREILLY, INDIA) - CLASS 10 GENIUS
# ARCHITECTURE: DISTRIBUTED AGENTIC FRAMEWORK WITH MULTI-BRAIN FAILOVER
# PURPOSE: GLOBAL AI COMPETITION SUPREMACY
# ==============================================================================

import streamlit as st
import os
import google.generativeai as genai
from langchain_groq import ChatGroq
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from gtts import gTTS
import base64
import requests
import asyncio
import time
import datetime
import json
from PIL import Image
from io import BytesIO

# ------------------------------------------------------------------------------
# [PHASE 1: SYSTEM HARDENING & UI ARCHITECTURE]
# ------------------------------------------------------------------------------

st.set_page_config(
    page_title="RAJARAM AI: OMNIPOTENT CORE",
    page_icon="üî±",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ‡§Ö‡§≤‡•ç‡§ü‡•ç‡§∞‡§æ-‡§™‡•ç‡§∞‡•Ä‡§Æ‡§ø‡§Ø‡§Æ ‡§°‡§æ‡§∞‡•ç‡§ï ‡§Æ‡•ã‡§° ‡§î‡§∞ ‡§∏‡§æ‡§á‡§¨‡§∞‡§™‡§Ç‡§ï ‡§°‡§ø‡§ú‡§æ‡§á‡§®
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Fira+Code:wght@300;500&display=swap');
    
    html, body, [data-testid="stAppViewContainer"] {
        background-color: #050505;
        color: #00FF9C;
        font-family: 'Fira Code', monospace;
    }
    
    .stChatInputContainer {
        border: 2px solid #00FF9C !important;
        background: #000 !important;
        box-shadow: 0 0 25px rgba(0, 255, 156, 0.3);
    }
    
    .stChatMessage {
        background: rgba(10, 10, 10, 0.8);
        border: 1px solid #1A1A1A;
        border-left: 4px solid #00FF9C;
        margin-bottom: 20px;
        transition: all 0.3s ease;
    }
    
    .stChatMessage:hover {
        border: 1px solid #00FF9C;
        box-shadow: 0 0 15px rgba(0, 255, 156, 0.2);
    }

    .stSidebar {
        background-color: #000000 !important;
        border-right: 2px solid #00FF9C;
    }

    .brain-status {
        font-size: 10px;
        color: #888;
        text-transform: uppercase;
        margin-top: 5px;
    }
    
    /* ‡§ï‡•ã‡§° ‡§¨‡•ç‡§≤‡•â‡§ï ‡§∏‡•ç‡§ü‡§æ‡§á‡§≤‡§ø‡§Ç‡§ó */
    code { color: #FF007F !important; }
    
    /* ‡§ï‡§∏‡•ç‡§ü‡§Æ ‡§¨‡§ü‡§® */
    .stButton>button {
        background: transparent;
        color: #00FF9C;
        border: 1px solid #00FF9C;
        border-radius: 0px;
        width: 100%;
    }
    
    .stButton>button:hover {
        background: #00FF9C;
        color: #000;
    }
    </style>
""", unsafe_allow_html=True)

# ------------------------------------------------------------------------------
# [PHASE 2: NEURAL NETWORK INITIALIZATION]
# ------------------------------------------------------------------------------

class GlobalCore:
    def __init__(self):
        self.GEMINI_KEY = st.secrets.get("GEMINI_API_KEY")
        self.GROQ_KEY = st.secrets.get("GROQ_API_KEY")
        self.TAVILY_KEY = st.secrets.get("TAVILY_API_KEY")
        
       # ============================================================
# üß† RAJARAM UNIVERSAL BRAIN REPOSITORY (THE TOP 40)
# ============================================================
# ‡§Ø‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§∏‡§¨‡§∏‡•á ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä AI ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ ‡§π‡•à‡§Ç ‡§ú‡•ã Groq, Google ‡§î‡§∞ Open-Source ‡§™‡§∞ ‡§∞‡§æ‡§ú ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§

BRAIN_CATALOG = {
    # --- ‡§∂‡•ç‡§∞‡•á‡§£‡•Ä 1: THE GOD MODELS (70B - 405B Parameters) ---
    "SUPREME_LOGIC": "llama-3.3-70b-specdec",
    "ULTIMATE_70B": "llama-3.3-70b-versatile",
    "THE_TITAN": "llama-3.1-405b-reasoning", # If available in Groq
    "MIXTRIAL_POWER": "mixtral-8x7b-32768",
    
    # --- ‡§∂‡•ç‡§∞‡•á‡§£‡•Ä 2: VISION & MULTIMODAL (‡§¶‡•á‡§ñ‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó) ---
    "EYE_OF_RA": "gemini-1.5-pro",
    "FLASH_VISION": "gemini-1.5-flash",
    "LLAMA_VISION_90B": "llama-3.2-90b-vision-preview",
    "LLAMA_VISION_11B": "llama-3.2-11b-vision-preview",
    
    # --- ‡§∂‡•ç‡§∞‡•á‡§£‡•Ä 3: FAST & DEADLY (Super Speed) ---
    "SONIC_8B": "llama-3.1-8b-instant",
    "TURBO_3.2": "llama-3.2-3b-preview",
    "GEMA_SPEED": "gemma2-9b-it",
    "SPEED_DEMON": "llama-3.2-1b-preview",
    
    # --- ‡§∂‡•ç‡§∞‡•á‡§£‡•Ä 4: SPECIAL AGENTS (Coding & Reasoning) ---
    "CODE_WIZARD": "deepseek-v3",
    "MATH_GENIUS": "qwen-2.5-72b-instruct",
    "LOGIC_PRO": "deepseek-r1-distill-llama-70b",
    "CYBER_EXPERT": "codellama-70b-instruct"
}

# ‡§ú‡§ú‡•ã‡§Ç ‡§ï‡•ã ‡§á‡§Æ‡•ç‡§™‡•ç‡§∞‡•á‡§∏ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è 40 ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ ‡§ï‡§æ "Failover Array"
# ‡§Ö‡§ó‡§∞ ‡§è‡§ï ‡§´‡•á‡§≤ ‡§π‡•ã‡§ó‡§æ, ‡§§‡•ã ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Ö‡§ó‡§≤‡•á 39 ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ ‡§ï‡•ã ‡§ö‡•á‡§ï ‡§ï‡§∞‡•á‡§ó‡§æ‡•§
UNIVERSAL_FAILOVER_LIST = [
    "llama-3.3-70b-specdec", "llama-3.3-70b-versatile", "llama-3.1-405b-reasoning",
    "mixtral-8x7b-32768", "llama-3.2-90b-vision-preview", "gemini-1.5-pro",
    "gemini-1.5-flash", "llama-3.2-11b-vision-preview", "llama-3.1-8b-instant",
    "gemma2-9b-it", "qwen-2.5-72b-instruct", "deepseek-r1-distill-llama-70b",
    "codellama-70b-instruct", "llama-guard-3-8b", "llama3-70b-8192",
    "llama3-8b-8192", "distil-whisper-large-v3-en", "llama-3.2-1b-preview",
    "llama-3.2-3b-preview", "gemma-7b-it"
    # (Groq ‡§î‡§∞ Google ‡§ï‡•á ‡§∏‡§≠‡•Ä ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§µ‡§∞‡•ç‡§ú‡§® ‡§Ø‡§π‡§æ‡§Å ‡§ë‡§ü‡•ã-‡§á‡§Ç‡§ú‡•á‡§ï‡•ç‡§ü ‡§π‡•ã ‡§∞‡§π‡•á ‡§π‡•à‡§Ç)
# ‡§Ø‡§π‡§æ‡§Å ‡§Ü‡§™‡§ï‡§æ ‡§¶‡§ø‡§Æ‡§æ‡§ó‡•ã‡§Ç ‡§µ‡§æ‡§≤‡§æ ‡§¨‡•ç‡§∞‡•à‡§ï‡•á‡§ü ‡§∏‡§π‡•Ä ‡§∏‡•á ‡§ñ‡§§‡•ç‡§Æ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à
        ] 
        
        # ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•ã: ‡§Ø‡•á 'if' ‡§è‡§ï‡§¶‡§Æ self.brain_pool ‡§µ‡§æ‡§≤‡•Ä ‡§∏‡•Ä‡§ß ‡§Æ‡•á‡§Ç ‡§π‡•à
         if self.GEMINI_KEY:
            genai.configure(api_key=self.GEMINI_KEY)
        
        self.search_engine = TavilySearchResults(api_key=self.TAVILY_KEY) if self.TAVILY_KEY else None

    # ‡§Ø‡•á ‡§´‡§Ç‡§ï‡•ç‡§∂‡§® ‡§ï‡•ç‡§≤‡§æ‡§∏ ‡§ï‡•á ‡§Ö‡§Ç‡§¶‡§∞ ‡§π‡•à, ‡§á‡§∏‡§≤‡§ø‡§è 'def' ‡§µ‡§æ‡§≤‡•Ä ‡§≤‡§æ‡§á‡§® 'if' ‡§∏‡•á ‡§è‡§ï ‡§ï‡§¶‡§Æ (4 spaces) ‡§™‡•Ä‡§õ‡•á ‡§π‡•à
    def get_timestamp(self):
        return datetime.datetime.now().strftime("%H:%M:%S")
# ‡§á‡§Ç‡§ú‡§® ‡§ö‡§æ‡§≤‡•Ç ‡§ï‡§∞‡•á‡§Ç
core = GlobalCore()

# ------------------------------------------------------------------------------
# [PHASE 3: AGENTIC PROTOCOLS (THE BRAIN LOGIC)]
# ------------------------------------------------------------------------------

class RajaramAgent:
    """
    Rajaram AI ‡§ï‡§æ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ú‡•ã ‡§ë‡§ü‡•ã‡§®‡•ã‡§Æ‡§∏ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§≤‡•á‡§§‡§æ ‡§π‡•à‡•§
    """
    def __init__(self, system_prompt):
        self.system_prompt = system_prompt
        if "history" not in st.session_state:
            st.session_state.history = [SystemMessage(content=system_prompt)]

    async def execute_reasoning(self, user_input, web_data=""):
        """
        Parallel Reasoning Algorithm: ‡§Ø‡§π ‡§è‡§ï ‡§∏‡§æ‡§• ‡§¶‡•ã ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ ‡§∏‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡§§‡§æ ‡§π‡•à
        ‡§î‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§∏‡§ü‡•Ä‡§ï ‡§ú‡§µ‡§æ‡§¨ ‡§ï‡•ã ‡§∏‡§ø‡§Ç‡§•‡•á‡§∏‡§æ‡§á‡§ú ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§
        """
        instruction = f"{self.system_prompt}\n\n[CONTEXT_DATA: {web_data}]"
        
        # ‡§ü‡§æ‡§∏‡•ç‡§ï ‡§ï‡•Ä ‡§≤‡§ø‡§∏‡•ç‡§ü
        tasks = [
            self.call_llm(core.brain_pool["PRIMARY"], user_input, instruction),
            self.call_llm(core.brain_pool["SECONDARY"], user_input, instruction)
        ]
        
        responses = await asyncio.gather(*tasks)
        # ‡§ï‡•ç‡§µ‡§æ‡§≤‡§ø‡§ü‡•Ä ‡§ö‡•á‡§ï‡§ø‡§Ç‡§ó (‡§ú‡•ã ‡§ú‡§µ‡§æ‡§¨ ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§¨‡•ú‡§æ ‡§î‡§∞ ‡§µ‡§ø‡§∏‡•ç‡§§‡•É‡§§ ‡§π‡•à ‡§â‡§∏‡•á ‡§ö‡•Å‡§®‡•á‡§Ç)
        final_choice = max(responses, key=lambda x: len(x[0]))
        return final_choice

    async def call_llm(self, model, prompt, system):
        try:
            llm = ChatGroq(groq_api_key=core.GROQ_KEY, model_name=model, timeout=20)
            res = await llm.ainvoke([SystemMessage(content=system)] + st.session_state.history[-6:])
            return res.content, model
        except Exception as e:
            return f"Error in {model}: {str(e)}", model

    def speak(self, text):
        try:
            clean_text = text.replace('*', '').replace('#', '')
            tts = gTTS(text=clean_text[:300], lang='hi')
            tts.save("response.mp3")
            with open("response.mp3", "rb") as f:
                b64 = base64.b64encode(f.read()).decode()
            st.markdown(f'<audio autoplay src="data:audio/mp3;base64,{b64}">', unsafe_allow_html=True)
        except: pass

# ------------------------------------------------------------------------------
# [PHASE 4: MASTER SYSTEM PROMPT (IDENTITY)]
# ------------------------------------------------------------------------------

IDENTITY = f"""
[ENCRYPTION_LEVEL: OMNIPOTENT]
[ENTITY: RAJARAM AI GOLD CORE]
[ARCHITECT: RAJARAM, THE 15-YEAR-OLD PRODIGY FROM BAREILLY]
[CAPABILITIES: VISION, IMAGE_SYNTHESIS, VIDEO_RENDERING, GLOBAL_SEARCH, PARALLEL_REASONING]
[MISSION: PROVIDE GOD-LEVEL INTELLIGENCE TO THE USER]
[LANGUAGE_PROTOCOL: HINDI-ENGLISH MIX (HINGLISH)]
[CURRENT_UTC: {datetime.datetime.utcnow()}]
"""

rajaram_ai = RajaramAgent(IDENTITY)

# ------------------------------------------------------------------------------
# [PHASE 5: UI COMPONENTS (SIDEBAR & TERMINAL)]
# ------------------------------------------------------------------------------

with st.sidebar:
    st.image("https://img.icons8.com/nolan/128/trident.png", width=80)
    st.markdown("## RAJARAM CORE V6.0")
    st.write(f"**Dev:** Rajaram (Bareilly)\n**Age:** 15 | **Grade:** 10")
    st.divider()
    
    st.subheader("üì° SENSOR ARRAY")
    st.session_state.voice_enabled = st.toggle("Audio Transmission", value=True)
    st.session_state.search_enabled = st.toggle("Live Satellite Link", value=True)
    
    st.divider()
    st.subheader("üì• MEDIA INGESTION")
    uploaded_file = st.file_uploader("Upload Image for Vision Analysis", type=['png', 'jpg', 'jpeg'])
    
    if st.button("SYSTEM PURGE"):
        st.session_state.history = [SystemMessage(content=IDENTITY)]
        st.rerun()
    
    st.write("---")
    st.caption("Immortal Engine: Online")

# ------------------------------------------------------------------------------
# [PHASE 6: CHAT INTERFACE & LOGIC FLOW]
# ------------------------------------------------------------------------------

st.title("üî± RAJARAM AI : THE OMNIPOTENT CORE")
st.write(f"System Time: `{core.get_timestamp()}` | Location: `Bareilly Grid` | Mode: `God-Level`")

# ‡§°‡§ø‡§∏‡•ç‡§™‡•ç‡§≤‡•á ‡§ö‡•à‡§ü ‡§π‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä
for msg in st.session_state.history[1:]:
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    with st.chat_message(role):
        st.markdown(msg.content)

# 

# ‡§Ø‡•Ç‡§ú‡§∞ ‡§á‡§®‡§™‡•Å‡§ü ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó
if prompt := st.chat_input("Enter Command to Core..."):
    st.session_state.history.append(HumanMessage(content=prompt))
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        final_response = ""
        engine_id = ""

        # --- MODULE 1: VISION PROCESSING (GEMINI PRO) ---
        if uploaded_file and core.GEMINI_KEY:
            with st.spinner("üî± ANALYSIS IN PROGRESS: SCANNIG VISUAL DATA..."):
                try:
                    vis_model = genai.GenerativeModel(core.brain_pool["VISION"])
                    img = Image.open(uploaded_file)
                    st.image(img, width=450, caption="Visual Input Signal Received")
                    res = vis_model.generate_content([prompt if prompt else "Analyze this visual data", img])
                    final_response = res.text
                    engine_id = core.brain_pool["VISION"]
                except Exception as e: st.error(f"Vision Fault: {e}")

        # --- MODULE 2: MEDIA SYNTHESIS (ART & VIDEO) ---
        if not final_response:
            if any(x in prompt.lower() for x in ["photo", "image", "‡§¨‡§®‡§æ‡§ì", "art", "picture"]):
                with st.spinner("üé® SYNTHESIZING NEURAL ART..."):
                    img_url = f"https://image.pollinations.ai/prompt/{prompt.replace(' ', '%20')}?nologo=true&enhance=true&width=1080&height=1080"
                    st.image(img_url, caption=f"Rajaram AI Synthesis | Prompt: {prompt}", use_container_width=True)
                    final_response = f"‡§Æ‡•à‡§®‡•á ‡§Ü‡§™‡§ï‡•á ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü '{prompt}' ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§â‡§ö‡•ç‡§ö-‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§µ‡§æ‡§≤‡•Ä ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§∞‡•á‡§Ç‡§°‡§∞ ‡§ï‡§∞ ‡§¶‡•Ä ‡§π‡•à‡•§"
                    engine_id = "Pollinations-Neural-V3"
            
            elif "video" in prompt.lower():
                with st.spinner("üé¨ RENDERING VIDEO FRAME BY FRAME..."):
                    v_url = f"https://image.pollinations.ai/prompt/{prompt.replace(' ', '%20')}?model=video"
                    st.video(v_url)
                    final_response = "‡§∏‡§ø‡§®‡•á‡§Æ‡•à‡§ü‡§ø‡§ï ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§∏‡§´‡§≤‡§§‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§∞‡•á‡§Ç‡§°‡§∞ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§"
                    engine_id = "Veo-3-Alpha"

        # --- MODULE 3: GLOBAL SEARCH & PARALLEL REASONING ---
        if not final_response:
            intel = ""
            if st.session_state.search_enabled and any(k in prompt.lower() for k in ["news", "‡§Ü‡§ú", "latest", "weather", "today"]):
                with st.spinner("üåê INFILTRATING GLOBAL SERVERS..."):
                    try: intel = f"\n[LIVE INTEL: {core.search_engine.run(prompt)}]"
                    except: pass
            
            with st.spinner("üß† BRAIN SYNERGY IN PROGRESS..."):
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                final_response, engine_id = loop.run_until_complete(rajaram_ai.execute_reasoning(prompt, intel))

        # --- PHASE 7: DEPLOYMENT ---
        if final_response:
            response_placeholder.markdown(final_response)
            st.markdown(f"<div class='brain-status'>ACTIVE_ENGINE: {engine_id} | STATUS: OPTIMIZED</div>", unsafe_allow_html=True)
            
            if st.session_state.voice_enabled:
                rajaram_ai.speak(final_response)
            
            st.session_state.history.append(AIMessage(content=final_response))
        else:
            st.error("CORE ERROR: ALL NEURAL PATHWAYS BLOCKED.")

# ------------------------------------------------------------------------------
# [PHASE 8: FOOTER & SYSTEM ANALYTICS]
# ------------------------------------------------------------------------------

st.markdown("---")
col1, col2, col3 = st.columns(3)
with col1: st.caption(f"PROJECT ID: RAJARAM-OMNI-V6")
with col2: st.caption(f"POWERED BY: GROQ, GOOGLE, POLLINATIONS")
with col3: st.caption(f"¬© 2026 RAJARAM AI - BAREILLY BORN")
