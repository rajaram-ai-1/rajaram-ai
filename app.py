import streamlit as st
import requests
import time

# 1. ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§à ‡§ï‡§æ ‡§Æ‡§ø‡§∂‡§® ‡§∏‡•á‡§ü‡§Ö‡§™
st.set_page_config(page_title="RAJARAM AI: LITE", page_icon="‚ö°", layout="wide")

# 2. ‡§≤‡•Å‡§ï ‡§î‡§∞ ‡§´‡•Ä‡§≤
st.markdown("""
    <style>
    .stApp { background-color: #0e1117; }
    .main-header { color: #00ffcc; font-size: 35px; font-weight: bold; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

# 3. ‡§∏‡§æ‡§á‡§°‡§¨‡§æ‡§∞ ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§™‡§π‡§ö‡§æ‡§®
with st.sidebar:
    st.markdown("### üõ†Ô∏è MISSION CONTROL")
    st.write(f"**Developer:** Rajaram (Bareilly)")
    st.write(f"**Age:** 15 | **Class:** 10th")
    st.success("Target: Lightest Brain Active")

st.markdown("<div class='main-header'>‚ö° RAJARAM AI: FAST MODE</div>", unsafe_allow_html=True)

# 4. ‡§§‡§ø‡§ú‡•ã‡§∞‡•Ä ‡§∏‡•á ‡§ö‡§æ‡§¨‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡§æ
HF_TOKEN = st.secrets.get("HF_TOKEN")

# 5. ‡§ö‡•à‡§ü ‡§π‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•Ä
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 6. ‡§π‡•Å‡§ï‡•ç‡§Æ ‡§î‡§∞ Google Gemma ‡§ï‡§æ ‡§¶‡§ø‡§Æ‡§æ‡§ó
if prompt := st.chat_input("Puchiye Maalik..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        if HF_TOKEN:
            # DUNIA KA SABSE HALKA DIMAG: Google Gemma 2B
            API_URL = "https://api-inference.huggingface.co/models/google/gemma-1.1-2b-it"
            headers = {"Authorization": f"Bearer {HF_TOKEN}"}
            
            # ‡§Ü‡§™‡§ï‡•Ä ‡§¨‡§∞‡•á‡§≤‡•Ä ‡§µ‡§æ‡§≤‡•Ä ‡§™‡§π‡§ö‡§æ‡§®
            system_info = "Tu Rajaram AI hai. Tera maalik Rajaram (15 saal, 10th class, Bareilly) hai. Tu bahut fast aur chota model hai par dimag tez hai."
            
            payload = {
                "inputs": f"{system_info}\nUser: {prompt}\nAI:",
                "parameters": {"max_new_tokens": 250, "temperature": 0.6}
            }
            
            try:
                response = requests.post(API_URL, headers=headers, json=payload)
                if response.status_code == 200:
                    result = response.json()
                    # Gemma ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§ï‡§æ ‡§§‡§∞‡•Ä‡§ï‡§æ
                    ai_reply = result[0]['generated_text'].split("AI:")[-1].strip()
                else:
                    ai_reply = f"Maalik, server thoda slow hai (Error: {response.status_code}). Ek baar phir enter dabaiye!"
            except:
                ai_reply = "‚ö†Ô∏è Link toot gaya, phir se koshish karein."
        else:
            ai_reply = "Maalik, Secrets mein HF_TOKEN nahi mila."

        # ‡§ü‡§æ‡§á‡§™‡§ø‡§Ç‡§ó ‡§á‡§´‡•á‡§ï‡•ç‡§ü
        for i in range(len(ai_reply)):
            message_placeholder.markdown(ai_reply[:i+1] + "‚ñå")
            time.sleep(0.01)
        message_placeholder.markdown(ai_reply)
    
    st.session_state.messages.append({"role": "assistant", "content": ai_reply})
