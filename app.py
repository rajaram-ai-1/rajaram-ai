import streamlit as st
import base64  # ‡§Ø‡§π ‡§´‡•ã‡§ü‡•ã ‡§ï‡•ã ‡§ï‡•ã‡§° ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•à
from PIL import Image
from groq import Groq
import streamlit as st
# ‡§Ø‡§π ‡§≤‡§æ‡§á‡§® ‡§∏‡§¨‡§∏‡•á ‡§ú‡§∞‡•Ç‡§∞‡•Ä ‡§π‡•à, ‡§á‡§∏‡•á ‡§Æ‡§ø‡§∏ ‡§Æ‡§§ ‡§ï‡§∞‡§®‡§æ ‡§≠‡§æ‡§à
from streamlit_mic_recorder import mic_recorder 

# --- ‡§¨‡§æ‡§ï‡•Ä ‡§ï‡§æ ‡§∏‡•á‡§ü‡§Ö‡§™ ---
import speech_recognition as rgn
import io

# 1. ‡§Æ‡§æ‡§á‡§ï ‡§î‡§∞ ‡§á‡§®‡§™‡•Å‡§ü ‡§ï‡§æ ‡§∏‡•á‡§ü‡§Ö‡§™
c1, c2 = st.columns([1, 8])

with c1:
    # ‡§Ø‡§π‡§æ‡§Å ‡§Ö‡§¨ NameError ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§è‡§ó‡§æ ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§π‡§Æ‡§®‡•á ‡§ä‡§™‡§∞ mic_recorder ‡§á‡§Æ‡•ç‡§™‡•ã‡§∞‡•ç‡§ü ‡§ï‡§∞ ‡§≤‡§ø‡§Ø‡§æ ‡§π‡•à
    audio_data = mic_recorder(start_prompt="üé§", stop_prompt="‚úÖ", key='voice_input_v3')

with c2:
    prompt = st.chat_input("rajaram ai se puche...")

# 2. ‡§Ü‡§µ‡§æ‡•õ ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§¶‡§ø‡§Æ‡§æ‡§ó
def translate_voice(audio_bytes):
    import speech_recognition as rgn
    import io
    
    recognizer = rgn.Recognizer()
    # ‡§Ø‡§π‡§æ‡§Å ‡§π‡§Æ AudioData ‡§ï‡§æ ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á ‡§ú‡•ã ‡§∏‡•Ä‡§ß‡§æ bytes ‡§∏‡§Æ‡§ù‡§§‡§æ ‡§π‡•à
    try:
        # ‡§π‡§Æ ‡§Æ‡§æ‡§® ‡§ï‡•á ‡§ö‡§≤ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó 16000Hz ‡§™‡§∞ ‡§π‡•à (Standard)
        audio_data = rgn.AudioData(audio_bytes, 16000, 2) 
        return recognizer.recognize_google(audio_data, language='hi-IN')
    except Exception as e:
        # ‡§Ö‡§ó‡§∞ ‡§ï‡•Å‡§õ ‡§∏‡§Æ‡§ù ‡§® ‡§Ü‡§è ‡§§‡•ã ‡§ñ‡§æ‡§≤‡•Ä ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§≠‡•á‡§ú‡•á‡§Ç
        return ""
# 3. ‡§≤‡•â‡§ú‡§ø‡§ï ‡§ú‡•ã ‡§ü‡§æ‡§á‡§™‡§ø‡§Ç‡§ó ‡§î‡§∞ ‡§Ü‡§µ‡§æ‡•õ ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Ç‡§≠‡§æ‡§≤‡•á‡§ó‡§æ
if audio_data:
    voice_result = translate_voice(audio_data['bytes'])
    if voice_result:
        prompt = voice_result
        st.info(f"üé§ ‡§Æ‡•à‡§Ç‡§®‡•á ‡§∏‡•Å‡§®‡§æ: {voice_result}")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    with st.spinner("rajaram ai  ‡§∏‡•ã‡§ö ‡§∞‡§π‡§æ ‡§π‡•à..."):
        # ‡§Ø‡§π‡§æ‡§Å ‡§Ü‡§™‡§ï‡§æ Groq/Llama ‡§µ‡§æ‡§≤‡§æ ‡§´‡§Ç‡§ï‡•ç‡§∂‡§® ‡§ï‡•â‡§≤ ‡§π‡•ã‡§ó‡§æ
        answer, _ = get_response(st.session_state.messages)

    st.session_state.messages.append({"role": "assistant", "content": answer})
    with st.chat_message("assistant"):
        st.write(answer)
    
    st.rerun()
    
# 1. ‡§™‡•á‡§ú ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó (‡§∏‡§¨‡§∏‡•á ‡§ä‡§™‡§∞)
st.set_page_config(page_title="Rajaram AI", page_icon="üëë", layout="centered")

# --- ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§à ‡§ï‡§æ '‡§¶‡§ø‡§Æ‡§æ‡§ó' ‡§ö‡•Å‡§®‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§á‡§Ç‡§ú‡§® (‡§®‡§Ø‡§æ ‡§ú‡•ã‡§°‡§º‡§æ ‡§ó‡§Ø‡§æ) ---
def select_best_brain(messages_history):
    user_input = messages_history[-1]["content"].lower()
    if any(word in user_input for word in ["padhai", "maths", "science", "exam", "book", "class", "study"]):
        return "llama-3.3-70b-versatile", "üìñ ‡§™‡§¢‡§º‡§æ‡§à ‡§µ‡§æ‡§≤‡§æ ‡§¶‡§ø‡§Æ‡§æ‡§ó (Llama 70B)"
    elif any(word in user_input for word in ["majak", "joke", "funny", "hi", "hello", "kaise ho"]):
        return "llama-3.1-8b-instant", "üòÇ ‡§ö‡•Å‡§≤‡§¨‡•Å‡§≤‡§æ ‡§¶‡§ø‡§Æ‡§æ‡§ó (Llama 8B)"
    else:
        return "llama-3.3-70b-versatile", "üß† ‡§ú‡•ç‡§û‡§æ‡§®‡•Ä ‡§¶‡§ø‡§Æ‡§æ‡§ó (Mixtral)"

# 2. ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ï‡§µ‡§ö (‡§∏‡•ç‡§ü‡§æ‡§á‡§≤‡§ø‡§Ç‡§ó)
st.markdown("""
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .stAppDeployButton {display:none !important;}
    div[data-testid="stStatusWidget"] {display:none !important;}
    button[title="Manage app"] {display: none !important;}
    .viewerBadge_container__1QS13 {display: none !important;}
    </style>
    """, unsafe_allow_html=True)

# 3. ‡§§‡§ø‡§ú‡•ã‡§∞‡•Ä ‡§∏‡•á ‡§ö‡§æ‡§¨‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡§æ
try:
    if "GROQ_API_KEY" in st.secrets:
        client = Groq(api_key=st.secrets["GROQ_API_KEY"])
    else:
        st.error("‚ùå ‡§≠‡§æ‡§à, Secrets ‡§Æ‡•á‡§Ç 'GROQ_API_KEY' ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä!")
        st.stop()
except Exception as e:
    st.error(f"‚ùå ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§è‡§∞‡§∞: {e}")
    st.stop()

# 4. 25+ ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§¶‡§ø‡§Æ‡§æ‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§Æ‡§π‡§æ-‡§´‡•å‡§ú (‡§Ü‡§™‡§ï‡•Ä ‡§≤‡§ø‡§∏‡•ç‡§ü ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§π‡•à)
groq_army = [
    "llama-3.3-70b-versatile", "llama-3.1-70b-versatile", 
    "llama-3.2-90b-vision-preview", "llama-3.2-11b-vision-preview",
    "llama-3.2-3b-preview", "llama-3.2-1b-preview",
    "llama-3.1-8b-instant", "llama3-70b-8192", 
    "llama3-8b-8192", "mixtral-8x7b-32768", 
    "gemma2-9b-it", "gemma-7b-it",
    "llama-guard-3-8b", "distil-whisper-large-v3-en"
]

# 5. ‡§∞‡§ø‡§∏‡•ç‡§™‡•â‡§®‡•ç‡§∏ ‡§´‡§Ç‡§ï‡•ç‡§∂‡§® (‡§á‡§∏‡•á ‡§Æ‡•à‡§Ç‡§®‡•á ‡§Ü‡§™‡§ï‡•á ‡§™‡•Å‡§∞‡§æ‡§®‡•á ‡§ï‡•ã‡§° ‡§Æ‡•á‡§Ç ‡§´‡§ø‡§ü ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§π‡•à)
def get_response(messages_history):
    # ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§ö‡•Å‡§®‡§®‡§æ
    best_brain, brain_display_name = select_best_brain(messages_history)
    
    try:
        completion = client.chat.completions.create(
            model=best_brain,
            messages=messages_history,
            temperature=0.7,
            max_tokens=2048,
        )
        return completion.choices[0].message.content, brain_display_name
    except Exception as e:
        return f"‡§Æ‡§æ‡§´‡§º ‡§ï‡§∞‡§®‡§æ ‡§≠‡§æ‡§à, ‡§ó‡§°‡§º‡§¨‡§°‡§º ‡§π‡•ã ‡§ó‡§à: {e}", "Error"
def get_meta_vision_response(user_prompt, image_file): 
         (
    )
# 6. ‡§¶‡§∞‡§¨‡§æ‡§∞ ‡§ï‡•Ä ‡§∏‡§ú‡§æ‡§µ‡§ü
st.markdown("<h1 style='text-align: center;'>üëë Rajaram AI</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'><b>25+ ‡§Æ‡§π‡§æ-‡§∂‡§ï‡•ç‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡§æ ‡§ï‡§µ‡§ö - ‡§Ö‡§Æ‡§∞ ,‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§î‡§∞ ‡§§‡•á‡§ú‡§º</b></p>", unsafe_allow_html=True)

# 7. ‡§Ø‡§æ‡§¶‡§¶‡§æ‡§∂‡•ç‡§§
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "‡§§‡•Å‡§Æ '‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ AI' ‡§π‡•ã‡•§ ‡§î‡§∞ ‡§Ø‡§π ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§∞‡•á‡§≤‡•Ä ‡§ï‡•á ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§à ‡§®‡•á ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§π‡•à ‡§ú‡•ã 15 ‡§∏‡§æ‡§≤ ‡§ï‡•á ‡§ï‡•ç‡§≤‡§æ‡§∏ 10 ‡§ï‡•á ‡§∏‡•ç‡§ü‡•Ç‡§°‡•á‡§Ç‡§ü ‡§π‡•à‡§Ç, ‡§µ‡•á ‡§¨‡§π‡•Å‡§§ ‡§á‡§Ç‡§ü‡•á‡§≤‡§ø‡§ú‡•á‡§Ç‡§ü ‡§π‡•à‡§Ç‡•§‡§Ü‡§™‡§ï‡•ã ‡§™‡§¢‡§º‡§æ‡§à ‡§ï‡•ã ‡§ó‡§Ç‡§≠‡•Ä‡§∞‡§§‡§æ ‡§∏‡•á ‡§≤‡•á‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§ ‡§Ö‡§ó‡§∞ ‡§ï‡•ã‡§à ‡§ï‡§π‡•á ‡§ï‡§ø ‡§Æ‡•Å‡§ù‡•á ‡§á‡§∏ ‡§ï‡•ç‡§≤‡§æ‡§∏ ‡§ï‡•á ‡§á‡§∏ ‡§∏‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü ‡§ï‡•Ä ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä ‡§ï‡§∞‡§æ‡§ì, ‡§§‡•ã ‡§â‡§∏‡•á ‡§ü‡•Ä‡§ö‡§∞ ‡§ï‡•Ä ‡§§‡§∞‡§π ‡§∏‡§Æ‡§ù‡§æ‡§ì‡•§ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•ã ‡§î‡§∞ '‡§≠‡§æ‡§à' ‡§ï‡§π‡§ï‡§∞ ‡§∏‡§Æ‡•ç‡§Æ‡§æ‡§® ‡§¶‡•ã‡•§"}
    ]

# ‡§™‡•Å‡§∞‡§æ‡§®‡•Ä ‡§ö‡•à‡§ü ‡§¶‡§ø‡§ñ‡§æ‡§®‡§æ
for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
# --- ‡§Ø‡§π‡§æ‡§Å ‡§∏‡•á ‡§®‡§Ø‡§æ ‡§ï‡•ã‡§° ‡§∂‡•Å‡§∞‡•Ç (‡§á‡§∏‡•á 'for' ‡§≤‡•Ç‡§™ ‡§ï‡•á ‡§†‡•Ä‡§ï ‡§®‡•Ä‡§ö‡•á ‡§™‡•á‡§∏‡•ç‡§ü ‡§ï‡§∞‡•á‡§Ç) ---

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    with st.spinner("‡§´‡•å‡§ú ‡§Æ‡•ã‡§∞‡•ç‡§ö‡§æ ‡§∏‡§Ç‡§≠‡§æ‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à..."):
        # ‡§Ø‡§π‡§æ‡§Å ‡§Ü‡§™‡§ï‡§æ 'answer' ‡§î‡§∞ 'used_id' ‡§∏‡§π‡•Ä ‡§∏‡•á ‡§∏‡•á‡§ü ‡§π‡•ã ‡§ó‡§Ø‡§æ ‡§π‡•à
        answer, used_id = get_response(st.session_state.messages)
        st.toast(f"‡§Ö‡§≠‡•Ä {used_id} ‡§è‡§ï‡•ç‡§ü‡§ø‡§µ ‡§π‡•à!", icon='üî•')
        st.session_state.messages.append({"role": "assistant", "content": answer})
        with st.chat_message("assistant"):
            st.write(answer)
            st.caption(f"‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§∂‡§ï‡•ç‡§§‡§ø: {used_id}")
        
        st.rerun()
