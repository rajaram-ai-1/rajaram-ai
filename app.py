import streamlit as st
from groq import Groq
import random
from streamlit_mic_recorder import mic_recorder
from gtts import gTTS
import base64
def shakti_listen():
    audio = mic_recorder(start_prompt="üé§ ‡§¨‡•ã‡§≤‡§®‡§æ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç", stop_prompt="üõë ‡§∞‡•Å‡§ï‡•á‡§Ç", key='recorder')
    if audio:
        client = Groq(api_key=st.secrets["GROQ_API_KEY"])
        transcription = client.audio.transcriptions.create(
            file=("user_voice.wav", audio['bytes']),
            model="whisper-large-v3",
            language="hi"
        )
        return transcription.text
    return None

def shakti_speak(text):
    tts = gTTS(text=text, lang='hi')
    tts.save("reply.mp3")
    with open("reply.mp3", "rb") as f:
        data = base64.b64encode(f.read()).decode()
        st.markdown(f'<audio src="data:audio/mp3;base64,{data}" autoplay="true"></audio>', unsafe_allow_html=True)
# --- 1. ‡§∂‡§æ‡§π‡•Ä ‡§ï‡§µ‡§ö ‡§î‡§∞ ‡§°‡§ø‡•õ‡§æ‡§á‡§® (CSS) ---
st.set_page_config(page_title="Rajaram AI üëë", layout="centered")

st.markdown("""
    <style>
    header, footer, #MainMenu {visibility: hidden !important;}
    .stAppDeployButton {display:none !important;}
    [data-testid="stToolbar"] {display: none !important;}
    .main { background-color: #0b141a; color: white; }
    
    .user-bubble {
        background-color: #005c4b; color: white; padding: 15px;
        border-radius: 15px 15px 2px 15px; margin-bottom: 15px;
        border-right: 5px solid gold;
    }
    .ai-bubble {
        background-color: #202c33; color: white; padding: 15px;
        border-radius: 15px 15px 15px 2px; margin-bottom: 15px;
        border-left: 5px solid gold;
    }
    div[data-testid="stBottom"] { background-color: #111b21 !important; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. 30 ‡§¶‡§ø‡§Æ‡§æ‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§´‡•å‡§ú (Updated & Active Models) ---
# ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§Æ‡•à‡§Ç‡§®‡•á ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§µ‡•ã ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ ‡§∞‡§ñ‡•á ‡§π‡•à‡§Ç ‡§ú‡•ã ‡§Ö‡§≠‡•Ä ‡§ö‡§≤ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç
MODELS_ARMY = [
    "llama-3.3-70b-versatile", "llama-3.1-70b-versatile", "llama-3.1-8b-instant",
    "gemma2-9b-it", "llama-3.2-11b-vision-preview", "llama3-70b-8192", 
    "llama3-8b-8192", "distil-whisper-large-v3-en", "gemma-7b-it"
]

# --- 3. ‡§Æ‡§π‡§æ-‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂ (46 ‡§∂‡§ï‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å) ---
MAHA_PROMPT = "‡§§‡•Å‡§Æ ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ AI ‡§π‡•ã‡•§ ‡§∏‡•ç‡§µ‡§æ‡§Æ‡•Ä ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§à ‡§¨‡§∞‡•á‡§≤‡•Ä ‡§µ‡§æ‡§≤‡•á‡•§ ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§∞‡•Ä 46 ‡§∂‡§ï‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§π‡•à‡§Ç‡•§ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§à ‡§ï‡§π‡§ï‡§∞ ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•ã‡•§"

# --- 4. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§á‡§Ç‡§ú‡§®: ‡§ë‡§ü‡•ã-‡§∏‡•ç‡§µ‡§ø‡§ö ‡§î‡§∞ ‡§´‡•á‡§≤-‡§∏‡•á‡§´ ‡§ï‡•á ‡§∏‡§æ‡§• ---
def get_ai_response(messages):
    client = Groq(api_key=st.secrets["GROQ_API_KEY"])
    
    # ‡§¶‡§ø‡§Æ‡§æ‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§≤‡§ø‡§∏‡•ç‡§ü ‡§ï‡•ã ‡§∞‡•à‡§Ç‡§°‡§Æ ‡§ï‡§∞‡§®‡§æ ‡§§‡§æ‡§ï‡§ø ‡§≤‡•ã‡§° ‡§¨‡§Å‡§ü‡§æ ‡§∞‡§π‡•á
    shuffled_brains = MODELS_ARMY.copy()
    random.shuffle(shuffled_brains)
    
    # ‡§π‡§∞ ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§ï‡•ã ‡§Ü‡•õ‡§Æ‡§æ‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡§®‡§æ
    for brain in shuffled_brains:
        try:
            completion = client.chat.completions.create(
                model=brain,
                messages=[{"role": "system", "content": MAHA_PROMPT}] + messages,
                temperature=0.8
            )
            return completion.choices[0].message.content, brain
        except Exception as e:
            # ‡§Ö‡§ó‡§∞ ‡§Ø‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§ñ‡§∞‡§æ‡§¨ ‡§π‡•à, ‡§§‡•ã ‡§Ö‡§ó‡§≤‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§™‡§∞ ‡§ú‡§æ‡§ì
            continue
            
    return "‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§à, ‡§∏‡§≠‡•Ä 30 ‡§¶‡§ø‡§Æ‡§æ‡§ó‡•ã‡§Ç ‡§™‡§∞ ‡§¨‡§æ‡§π‡§∞‡•Ä ‡§π‡§Æ‡§≤‡§æ ‡§π‡•Å‡§Ü ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ï‡•Å‡§õ ‡§¶‡•á‡§∞ ‡§¨‡§æ‡§¶ ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§", "Error"

# --- 5. ‡§¶‡§∞‡§¨‡§æ‡§∞ (Interface) ---
def main():
   def main():
    st.title("üëë ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ AI LIVE")
    
    # ‡§Ø‡§π‡§æ‡§Å ‡§Æ‡§æ‡§á‡§ï ‡§¨‡§ü‡§® ‡§Ü‡§è‡§ó‡§æ
    user_voice_input = shakti_listen()
    
    # ‡§Ö‡§ó‡§∞ ‡§Ü‡§™‡§®‡•á ‡§ï‡•Å‡§õ ‡§¨‡•ã‡§≤‡§æ ‡§π‡•à, ‡§§‡•ã ‡§â‡§∏‡•á ‡§ö‡•à‡§ü ‡§á‡§®‡§™‡•Å‡§ü ‡§Æ‡§æ‡§® ‡§≤‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§è‡§ó‡§æ
    if user_voice_input:
        prompt = user_voice_input
        # ‡§á‡§∏‡§ï‡•á ‡§Ü‡§ó‡•á ‡§ï‡§æ ‡§Ü‡§™‡§ï‡§æ ‡§™‡•Å‡§∞‡§æ‡§®‡§æ ‡§ï‡•ã‡§° (Groq ‡§µ‡§æ‡§≤‡§æ) ‡§Ö‡§™‡§®‡•á ‡§Ü‡§™ ‡§ö‡§≤‡•á‡§ó‡§æ...
       
    st.markdown("<h1 style='text-align: center; color: gold;'>üëë ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ AI</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; color: gray;'>30 ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§´‡•á‡§≤-‡§∏‡•á‡§´ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø</p>", unsafe_allow_html=True)

    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§¶‡§ø‡§ñ‡§æ‡§ì
    for chat in st.session_state.chat_history:
        cls = "user-bubble" if chat["role"] == "user" else "ai-bubble"
        label = "‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§à" if chat["role"] == "user" else f"AI (‡§∂‡§ï‡•ç‡§§‡§ø: {chat.get('brain', '‡§Æ‡•Å‡§ñ‡•ç‡§Ø')})"
        st.markdown(f"<div class='{cls}'><b>{label}:</b><br>{chat['content']}</div>", unsafe_allow_html=True)

    # ‡§Ü‡§¶‡•á‡§∂ ‡§á‡§®‡§™‡•Å‡§ü
    prompt = st.chat_input("‡§Ü‡§¶‡•á‡§∂ ‡§¶‡•á‡§Ç, ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§à...")

    if prompt:
        # ‡§Ø‡•Ç‡§ú‡§∞ ‡§ï‡§æ ‡§Æ‡•à‡§∏‡•á‡§ú ‡§¶‡§ø‡§ñ‡§æ‡§ì
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        st.rerun()

    # AI ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ (‡§Ö‡§ó‡§∞ ‡§Ü‡§ñ‡§ø‡§∞‡•Ä ‡§Æ‡•à‡§∏‡•á‡§ú ‡§Ø‡•Ç‡§ú‡§∞ ‡§ï‡§æ ‡§π‡•à)
    if st.session_state.chat_history and st.session_state.chat_history[-1]["role"] == "user":
        with st.spinner("30 ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡§Ç‡§•‡§® ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
            # ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§Ø‡•Ç‡§ú‡§∞ ‡§î‡§∞ ‡§Ö‡§∏‡§ø‡§∏‡•ç‡§ü‡•á‡§Ç‡§ü ‡§ï‡•Ä ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§≠‡•á‡§ú‡§®‡§æ (‡§¨‡§ø‡§®‡§æ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü ‡§ï‡•á, ‡§µ‡•ã ‡§Ö‡§Ç‡§¶‡§∞ ‡§ú‡•Å‡•ú ‡§ú‡§æ‡§è‡§ó‡§æ)
            clean_messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.chat_history]
            
            ans, brain_used = get_ai_response(clean_messages)
            
            st.session_state.chat_history.append({"role": "assistant", "content": ans, "brain": brain_used})
            st.rerun()

if __name__ == "__main__":
    main()
