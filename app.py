import streamlit as st
from streamlit_mic_recorder import mic_recorder
from groq import Groq
import speech_recognition as rgn
import io

# --- 1. ‡§™‡•á‡§ú ‡§∏‡•á‡§ü‡§Ö‡§™ ‡§î‡§∞ ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ï‡§µ‡§ö ---
st.set_page_config(page_title="Rajaram AI", page_icon="üëë", layout="centered")

# CSS: ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§´‡§ø‡§ï‡•ç‡§∏ (‡§®‡§æ‡§Æ ‡§è‡§ï ‡§¨‡§æ‡§∞, ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§ü‡§æ‡§∏‡•ç‡§ï‡§¨‡§æ‡§∞ ‡§∏‡•á ‡§ä‡§™‡§∞)
st.markdown("""
    <style>
    #MainMenu, footer, header {visibility: hidden;}
    .stAppDeployButton {display:none !important;}
    
    .main { margin-bottom: 150px; }
    
    /* ‡§á‡§®‡§™‡•Å‡§ü ‡§ï‡§Ç‡§ü‡•á‡§®‡§∞: ‡§á‡§∏‡•á 70px ‡§ä‡§™‡§∞ ‡§∞‡§ñ‡§æ ‡§π‡•à ‡§§‡§æ‡§ï‡§ø ‡§ü‡§æ‡§∏‡•ç‡§ï‡§¨‡§æ‡§∞ ‡§á‡§∏‡•á ‡§® ‡§õ‡•Å‡§™‡•á */
    div[data-testid="stVerticalBlock"] > div:last-child {
        position: fixed;
        bottom: 70px; 
        left: 0;
        width: 100%;
        background-color: #0E1117;
        padding: 10px 8%;
        z-index: 1000;
        border-top: 2px solid #ff4b4b;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•Ä 30 ‡§∏‡§¨‡§∏‡•á ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§Æ‡§π‡§æ-‡§∂‡§ï‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å (Army) ---
# ‡§π‡§Æ‡§®‡•á ‡§Ø‡§π‡§æ‡§Å 30 ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ ‡§ï‡•Ä ‡§ï‡•à‡§™‡•á‡§¨‡§ø‡§≤‡§ø‡§ü‡•Ä ‡§ï‡•á ‡§π‡§ø‡§∏‡§æ‡§¨ ‡§∏‡•á ‡§≤‡§ø‡§∏‡•ç‡§ü ‡§¨‡§®‡§æ‡§à ‡§π‡•à
groq_army = [
    "llama-3.3-70b-versatile", "llama-3.3-70b-specdec", 
    "llama-3.1-70b-versatile", "llama-3.1-8b-instant",
    "llama-3.2-90b-vision-preview", "llama-3.2-11b-vision-preview",
    "llama-3.2-3b-preview", "llama-3.2-1b-preview",
    "mixtral-8x7b-32768", "gemma2-9b-it", 
    "gemma-7b-it", "llama-guard-3-8b",
    "distil-whisper-large-v3-en" # ‡§Ü‡§µ‡§æ‡•õ ‡§ï‡•á ‡§≤‡§ø‡§è
    # ‡§®‡•ã‡§ü: Groq ‡§™‡§∞ ‡§´‡§ø‡§≤‡§π‡§æ‡§≤ ‡§Ø‡•á ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§Æ‡•â‡§°‡§≤‡•ç‡§∏ ‡§π‡•à‡§Ç ‡§ú‡•ã 30+ ‡§¨‡•à‡§ï‡§Ö‡§™‡•ç‡§∏ ‡§ï‡•Ä ‡§§‡§∞‡§π ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç
]

# --- 3. ‡§∏‡§¨‡§∏‡•á ‡§§‡§æ‡§ï‡§§‡§µ‡§∞ ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§ö‡•Å‡§®‡§®‡•á ‡§ï‡§æ ‡§á‡§Ç‡§ú‡§® ---
def get_response(messages_history):
    # ‡§Ø‡§π ‡§á‡§Ç‡§ú‡§® ‡§™‡•Ç‡§∞‡•Ä ‡§´‡•å‡§ú ‡§ï‡•ã ‡§ö‡•á‡§ï ‡§ï‡§∞‡•á‡§ó‡§æ
    for model_name in groq_army:
        try:
            client = Groq(api_key=st.secrets["GROQ_API_KEY"])
            completion = client.chat.completions.create(
                model=model_name,
                messages=messages_history,
                temperature=0.6,
                max_tokens=4096,
            )
            return completion.choices[0].message.content, model_name
        except:
            continue # ‡§Ö‡§ó‡§∞ ‡§è‡§ï ‡§∏‡§ø‡§™‡§æ‡§π‡•Ä ‡§ó‡§ø‡§∞‡§æ, ‡§§‡•ã ‡§Ö‡§ó‡§≤‡§æ ‡§Æ‡•ã‡§∞‡•ç‡§ö‡§æ ‡§∏‡§Ç‡§≠‡§æ‡§≤‡•á‡§ó‡§æ
            
    return "‡§≠‡§æ‡§à, ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•Ä ‡§∏‡§æ‡§∞‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å ‡§Ö‡§≠‡•Ä ‡§¨‡§ø‡§ú‡•Ä ‡§π‡•à‡§Ç‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ö‡•á‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§", "Failed"

# --- 4. ‡§Ü‡§µ‡§æ‡•õ ‡§ï‡•ã ‡§∏‡§Æ‡§ù‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§¶‡§ø‡§Æ‡§æ‡§ó ---
def translate_voice(audio_bytes):
    recognizer = rgn.Recognizer()
    audio_file = io.BytesIO(audio_bytes)
    try:
        with rgn.AudioFile(audio_file) as source:
            audio = recognizer.record(source)
        return recognizer.recognize_google(audio, language='hi-IN')
    except:
        return None

# --- 5. ‡§¶‡§∞‡§¨‡§æ‡§∞ ‡§ï‡§æ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§ö‡•á‡§π‡§∞‡§æ (‡§∏‡§ø‡§∞‡•ç‡§´ ‡§è‡§ï ‡§¨‡§æ‡§∞) ---
st.markdown("<h1 style='text-align: center; color: #ff4b4b;'>üëë Rajaram AI</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'><b>30+ ‡§Æ‡§π‡§æ-‡§∂‡§ï‡•ç‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡§æ ‡§ï‡§µ‡§ö - ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä AI</b></p>", unsafe_allow_html=True)
st.markdown("---")

# ‡§Ø‡§æ‡§¶‡§¶‡§æ‡§∂‡•ç‡§§ (Chat History)
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "‡§§‡•Å‡§Æ ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ AI ‡§π‡•ã, ‡§ú‡§ø‡§∏‡•á ‡§¨‡§∞‡•á‡§≤‡•Ä ‡§ï‡•á ‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∏ ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§à ‡§®‡•á ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§π‡•à‡•§ ‡§§‡•Å‡§Æ ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§∏‡§¨‡§∏‡•á ‡§§‡§æ‡§ï‡§§‡§µ‡§∞ AI ‡§π‡•ã‡•§"}
    ]

# ‡§™‡•Å‡§∞‡§æ‡§®‡•á ‡§Æ‡•à‡§∏‡•á‡§ú ‡§¶‡§ø‡§ñ‡§æ‡§®‡§æ
for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

# --- 6. ‡§á‡§®‡§™‡•Å‡§ü ‡§ï‡§Ç‡§ü‡•ç‡§∞‡•ã‡§≤ (‡§®‡•Ä‡§ö‡•á ‡§´‡§ø‡§ï‡•ç‡§∏) ---
prompt = None
with st.container():
    c1, c2 = st.columns([1, 6])
    with c1:
        audio_data = mic_recorder(start_prompt="üé§", stop_prompt="‚úÖ", key='rajaram_army_v30')
    with c2:
        input_text = st.chat_input("‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ ‡§ï‡•á ‡§∏‡§¨‡§∏‡•á ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä AI ‡§∏‡•á ‡§™‡•Ç‡§õ‡•á‡§Ç...")

# --- 7. ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó ---
if audio_data:
    voice_text = translate_voice(audio_data['bytes'])
    if voice_text:
        prompt = voice_text
        st.info(f"üé§ ‡§∏‡•Å‡§®‡§æ ‡§ó‡§Ø‡§æ: {voice_text}")
elif input_text:
    prompt = input_text

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    with st.chat_message("assistant"):
        with st.spinner("30 ‡§Æ‡§π‡§æ-‡§∂‡§ï‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à‡§Ç..."):
            ans, brain_name = get_response(st.session_state.messages)
            st.write(ans)
            st.caption(f"‡§§‡•à‡§®‡§æ‡§§ ‡§∂‡§ï‡•ç‡§§‡§ø: {brain_name}")
            st.toast(f"‡§Æ‡•ã‡§∞‡•ç‡§ö‡§æ ‡§∏‡§Ç‡§≠‡§æ‡§≤‡§æ: {brain_name}", icon="üõ°Ô∏è")
    
    st.session_state.messages.append({"role": "assistant", "content": ans})
    st.rerun()
