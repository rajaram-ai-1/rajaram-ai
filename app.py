import streamlit as st
from groq import Groq

# 1. ‡§™‡•á‡§ú ‡§∏‡•á‡§ü‡§ø‡§Ç‡§ó (‡§∏‡§¨‡§∏‡•á ‡§ä‡§™‡§∞)
st.set_page_config(page_title="Rajaram AI", page_icon="üëë", layout="centered")

# --- ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§à ‡§ï‡§æ '‡§¶‡§ø‡§Æ‡§æ‡§ó' ‡§ö‡•Å‡§®‡§®‡•á ‡§µ‡§æ‡§≤‡§æ ‡§á‡§Ç‡§ú‡§® (‡§®‡§Ø‡§æ ‡§ú‡•ã‡§°‡§º‡§æ ‡§ó‡§Ø‡§æ) ---
def select_best_brain(messages_history):
    user_input = messages_history[-1]["content"].lower()
    if any(word in user_input for word in ["padhai", "maths", "science", "exam", "book", "class", "study"]):
        return "llama-3.3-70b-versatile", "üìñ ‡§™‡§¢‡§º‡§æ‡§à ‡§µ‡§æ‡§≤‡§æ ‡§¶‡§ø‡§Æ‡§æ‡§ó (Llama 70B)"
    elif any(word in user_input for word in ["majak", "joke", "funny", "hi", "hello", "kaise ho"]):
        return "llama-3.1-8b-instant", "üòÇ ‡§ö‡•Å‡§≤‡§¨‡•Å‡§≤‡§æ ‡§¶‡§ø‡§Æ‡§æ‡§ó (Llama 8B)"
    else:
        return "llama-3.1-70b-versatile", "üß† ‡§ú‡•ç‡§û‡§æ‡§®‡•Ä ‡§¶‡§ø‡§Æ‡§æ‡§ó (Mixtral)"

# 2. ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§æ ‡§ï‡§µ‡§ö (‡§∏‡•ç‡§ü‡§æ‡§á‡§≤‡§ø‡§Ç‡§ó)
st.markdown("""
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .stAppDeployButton {display:none !important;}
    div[data-testid="stStatusWidget"] {display:none !important;}
    button[title="Manage app"] {display: none !important;}
    .viewerBadge_container__1QS13 {display: none !important;}
    </style>
    """, unsafe_allow_html=True)

# 3. ‡§§‡§ø‡§ú‡•ã‡§∞‡•Ä ‡§∏‡•á ‡§ö‡§æ‡§¨‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡§æ
try:
    if "GROQ_API_KEY" in st.secrets:
        client = Groq(api_key=st.secrets["GROQ_API_KEY"])
    else:
        st.error("‚ùå ‡§≠‡§æ‡§à, Secrets ‡§Æ‡•á‡§Ç 'GROQ_API_KEY' ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä!")
        st.stop()
except Exception as e:
    st.error(f"‚ùå ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§è‡§∞‡§∞: {e}")
    st.stop()

# 4. 25+ ‡§∂‡§ï‡•ç‡§§‡§ø‡§∂‡§æ‡§≤‡•Ä ‡§¶‡§ø‡§Æ‡§æ‡§ó‡•ã‡§Ç ‡§ï‡•Ä ‡§Æ‡§π‡§æ-‡§´‡•å‡§ú (‡§Ü‡§™‡§ï‡•Ä ‡§≤‡§ø‡§∏‡•ç‡§ü ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§π‡•à)
groq_army = [
    "llama-3.3-70b-versatile", "llama-3.1-70b-versatile", 
    "llama-3.2-90b-vision-preview", "llama-3.2-11b-vision-preview",
    "llama-3.2-3b-preview", "llama-3.2-1b-preview",
    "llama-3.1-8b-instant", "llama3-70b-8192", 
    "llama3-8b-8192", "mixtral-8x7b-32768", 
    "gemma2-9b-it", "gemma-7b-it",
    "llama-guard-3-8b", "distil-whisper-large-v3-en"
]

# 5. ‡§∞‡§ø‡§∏‡•ç‡§™‡•â‡§®‡•ç‡§∏ ‡§´‡§Ç‡§ï‡•ç‡§∂‡§® (‡§á‡§∏‡•á ‡§Æ‡•à‡§Ç‡§®‡•á ‡§Ü‡§™‡§ï‡•á ‡§™‡•Å‡§∞‡§æ‡§®‡•á ‡§ï‡•ã‡§° ‡§Æ‡•á‡§Ç ‡§´‡§ø‡§ü ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§π‡•à)
def get_response(messages_history):
    # ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§ö‡•Å‡§®‡§®‡§æ
    best_brain, brain_display_name = select_best_brain(messages_history)
    
    try:
        completion = client.chat.completions.create(
            model=best_brain,
            messages=messages_history,
            temperature=0.7,
            max_tokens=2048,
        )
        return completion.choices[0].message.content, brain_display_name
    except Exception as e:
        return f"‡§Æ‡§æ‡§´‡§º ‡§ï‡§∞‡§®‡§æ ‡§≠‡§æ‡§à, ‡§ó‡§°‡§º‡§¨‡§°‡§º ‡§π‡•ã ‡§ó‡§à: {e}", "Error"

# 6. ‡§¶‡§∞‡§¨‡§æ‡§∞ ‡§ï‡•Ä ‡§∏‡§ú‡§æ‡§µ‡§ü
st.markdown("<h1 style='text-align: center;'>üëë Rajaram AI</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'><b>25+ ‡§Æ‡§π‡§æ-‡§∂‡§ï‡•ç‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡§æ ‡§ï‡§µ‡§ö - ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§î‡§∞ ‡§§‡•á‡§ú‡§º</b></p>", unsafe_allow_html=True)

# 7. ‡§Ø‡§æ‡§¶‡§¶‡§æ‡§∂‡•ç‡§§
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "‡§§‡•Å‡§Æ '‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ AI' ‡§π‡•ã‡•§ ‡§î‡§∞ ‡§Ø‡§π ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§∞‡•á‡§≤‡•Ä ‡§ï‡•á ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§à ‡§®‡•á ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§π‡•à ‡§ú‡•ã 15 ‡§∏‡§æ‡§≤ ‡§ï‡•á ‡§ï‡•ç‡§≤‡§æ‡§∏ 10 ‡§ï‡•á ‡§∏‡•ç‡§ü‡•Ç‡§°‡•á‡§Ç‡§ü ‡§π‡•à‡§Ç, ‡§µ‡•á ‡§¨‡§π‡•Å‡§§ ‡§á‡§Ç‡§ü‡•á‡§≤‡§ø‡§ú‡•á‡§Ç‡§ü ‡§π‡•à‡§Ç‡•§ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞‡•ã ‡§î‡§∞ '‡§≠‡§æ‡§à' ‡§ï‡§π‡§ï‡§∞ ‡§∏‡§Æ‡•ç‡§Æ‡§æ‡§® ‡§¶‡•ã‡•§"}
    ]

# ‡§™‡•Å‡§∞‡§æ‡§®‡•Ä ‡§ö‡•à‡§ü ‡§¶‡§ø‡§ñ‡§æ‡§®‡§æ
for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

# 8. ‡§π‡•Å‡§ï‡•ç‡§Æ ‡§î‡§∞ ‡§ú‡§µ‡§æ‡§¨
prompt = st.chat_input("‡§π‡•Å‡§ï‡•ç‡§Æ ‡§ï‡§∞‡•á‡§Ç ‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§à...")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    with st.spinner("‡§´‡•å‡§ú ‡§Æ‡•ã‡§∞‡•ç‡§ö‡§æ ‡§∏‡§Ç‡§≠‡§æ‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à..."):
        # ‡§Ø‡§π‡§æ‡§Å ‡§Ü‡§™‡§ï‡§æ 'answer' ‡§î‡§∞ 'used_id' ‡§∏‡§π‡•Ä ‡§∏‡•á ‡§∏‡•á‡§ü ‡§π‡•ã ‡§ó‡§Ø‡§æ ‡§π‡•à
        answer, used_id = get_response(st.session_state.messages)
        st.session_state.messages.append({"role": "assistant", "content": answer})
        with st.chat_message("assistant"):
            st.write(answer)
            st.caption(f"‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§∂‡§ï‡•ç‡§§‡§ø: {used_id}")
        
        st.rerun()
