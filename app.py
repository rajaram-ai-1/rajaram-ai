import streamlit as st
import os
import google.generativeai as genai # ‡§ú‡•á‡§Æ‡§ø‡§®‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è
from langchain_groq import ChatGroq
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from gtts import gTTS
import base64
import requests 
import io       
from PIL import Image 

# 1. Page Configuration
st.set_page_config(page_title="Rajaram AI Gold", page_icon="üî±", layout="wide")

# Custom Styling
st.markdown("""
    <style>
    .main { background-color: #0e1117; }
    .stChatFloatingInputContainer { bottom: 20px; }
    </style>
""", unsafe_allow_html=True)

# 2. API Keys Loading
GROQ_KEY = st.secrets.get("GROQ_API_KEY")
TAVILY_KEY = st.secrets.get("TAVILY_API_KEY")
GEMINI_KEY = st.secrets.get("GEMINI_API_KEY") # ‡§ú‡•á‡§Æ‡§ø‡§®‡•Ä ‡§ï‡•Ä ‡§∏‡•Ä‡§ï‡•ç‡§∞‡•á‡§ü‡•ç‡§∏ ‡§∏‡•á ‡§â‡§†‡§æ‡§è‡§ó‡§æ
if not GEMINI_KEY:
    st.error("‡§ì‡§π! ‡§ú‡•á‡§Æ‡§ø‡§®‡•Ä ‡§ö‡§æ‡§¨‡•Ä (Key) ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ Secrets ‡§ö‡•á‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§")
else:
    st.success("‡§ú‡•á‡§Æ‡§ø‡§®‡•Ä ‡§ö‡§æ‡§¨‡•Ä ‡§∏‡§´‡§≤‡§§‡§æ‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§Æ‡§ø‡§≤ ‡§ó‡§à ‡§π‡•à! üî±")
if GEMINI_KEY:
    genai.configure(api_key=GEMINI_KEY)

# 3. ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§¶‡§ø‡§Æ‡§æ‡§ó (Multi-Brain) ‡§≤‡§ø‡§∏‡•ç‡§ü
BRAINS = [
    "llama-3.3-70b-versatile", 
    "llama-3.1-70b-versatile", 
    "llama-3.1-8b-instant",
    "mixtral-8x7b-32768"
]

# 4. Persona
SYSTEM_PROMPT = """You are Rajaram AI, a super-intelligent, self-improving AI entity.
CREATED BY: Rajaram, a brilliant 15-year-old Class 10 student from Bareilly, India.
POWERS: Multi-Brain, Vision, Video (Veo), Music (Lyria), and Self-Improvement.
TODAY'S DATE: February 27, 2026."""

if "chat_history" not in st.session_state:
    st.session_state.chat_history = [SystemMessage(content=SYSTEM_PROMPT)]

# Voice Function
def speak_text(text):
    try:
        tts = gTTS(text=text[:200], lang='hi')
        tts.save("response.mp3")
        with open("response.mp3", "rb") as f:
            data = f.read()
        b64 = base64.b64encode(data).decode()
        md = f'<audio autoplay="true" src="data:audio/mp3;base64,{b64}">'
        st.markdown(md, unsafe_allow_html=True)
    except: pass

# 5. Initialize Search
try:
    search = TavilySearchResults(api_key=TAVILY_KEY) if TAVILY_KEY else None
except: search = None

# 6. UI Header
st.title("üî± Rajaram AI Gold")
st.write(f"Developed by **Rajaram (Bareilly)** | Class 10 Student | Status: **Gemini 3 Flash Powered**")

# --- ‡§®‡§à ‡§∂‡§ï‡•ç‡§§‡§ø: ‡§™‡•ç‡§≤‡§∏ (+) ‡§¨‡§ü‡§® ‡§ö‡•à‡§ü‡§¨‡•â‡§ï‡•ç‡§∏ ‡§ï‡•á ‡§™‡§æ‡§∏ ---
# ‡§á‡§∏‡•á ‡§π‡§Æ‡§®‡•á ‡§µ‡§ø‡•õ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ö‡•à‡§ü ‡§á‡§®‡§™‡•Å‡§ü ‡§ï‡•á ‡§ä‡§™‡§∞ ‡§∞‡§ñ‡§æ ‡§π‡•à
with st.expander("‚ûï ‡§´‡•ã‡§ü‡•ã/‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç (AI ‡§á‡§∏‡•á ‡§¶‡•á‡§ñ‡•á‡§ó‡§æ)", expanded=False):
    uploaded_file = st.file_uploader("‡§Ø‡§π‡§æ‡§Å ‡§´‡§æ‡§á‡§≤ ‡§°‡§æ‡§≤‡•á‡§Ç", type=['png', 'jpg', 'jpeg', 'mp4'])

st.write("---")

# Display History
for message in st.session_state.chat_history[1:]:
    role = "user" if isinstance(message, HumanMessage) else "assistant"
    with st.chat_message(role):
        st.markdown(message.content)

# 7. Smart Logic
if prompt := st.chat_input("Ask Rajaram AI anything..."):
    # ‡§Ö‡§ó‡§∞ ‡§´‡•ã‡§ü‡•ã ‡§Ö‡§™‡§≤‡•ã‡§° ‡§π‡•à ‡§î‡§∞ ‡§Ø‡•Ç‡§ú‡§∞ ‡§®‡•á ‡§ï‡•Å‡§õ ‡§™‡•Ç‡§õ‡§æ ‡§π‡•à
    if uploaded_file and GEMINI_KEY:
        st.session_state.chat_history.append(HumanMessage(content=f"[Image Uploaded] {prompt}"))
        with st.chat_message("user"):
            st.image(uploaded_file, width=300)
            st.markdown(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("Rajaram AI ‡§´‡•ã‡§ü‡•ã ‡§¶‡•á‡§ñ ‡§∞‡§π‡§æ ‡§π‡•à..."):
                model = genai.GenerativeModel('gemini-1.5-flash') # Gemini Vision
                img = Image.open(uploaded_file)
                response = model.generate_content([prompt, img]) #
                final_response = response.text
                st.markdown(final_response)
                st.session_state.chat_history.append(AIMessage(content=final_response))
                if st.session_state.get("voice_on"): speak_text(final_response)

    else:
        # ‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§≤‡•â‡§ú‡§ø‡§ï (‡§Ü‡§™‡§ï‡§æ ‡§™‡•Å‡§∞‡§æ‡§®‡§æ ‡§µ‡§æ‡§≤‡§æ)
        st.session_state.chat_history.append(HumanMessage(content=prompt))
        with st.chat_message("user"): st.markdown(prompt)

        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            search_data = ""
            
            # A. ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§∏‡§∞‡•ç‡§ö
            live_keywords = ["news", "latest", "today", "weather", "score", "‡§Ü‡§ú", "‡§§‡§æ‡§ú‡§º‡§æ"]
            if search and any(word in prompt.lower() for word in live_keywords):
                with st.spinner("Searching Live Data..."):
                    try: search_data = f"\n\nLIVE SEARCH RESULTS (2026): {search.run(prompt)}"
                    except: search_data = ""

            # B. ‡§®‡§à ‡§∂‡§ï‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å (Video/Music/Image)
            final_response = ""
            active_brain = ""
            
            if any(x in prompt.lower() for x in ["video", "‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã"]):
                final_response = "üé¨ Veo AI ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à..." #
                active_brain = "Veo-Engine"
            
            elif any(x in prompt.lower() for x in ["music", "song", "‡§ó‡§æ‡§®‡§æ"]):
                final_response = "üéµ Lyria 3 ‡§Æ‡•ç‡§Ø‡•Ç‡§ú‡§ø‡§ï ‡§ï‡§Ç‡§™‡•ã‡§ú ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à..." #
                active_brain = "Lyria-3"
# --- ‡§Ö‡§∏‡§≤‡•Ä ‡§ú‡•á‡§Æ‡§ø‡§®‡•Ä ‡§á‡§Æ‡•á‡§ú ‡§ú‡§®‡§∞‡•á‡§∂‡§® (Nano Banana 2) ---
        elif any(x in prompt.lower() for x in ["photo", "image", "‡§¨‡§®‡§æ‡§ì", "‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞"]):
            with st.spinner("‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ AI (Nano Banana 2) ‡§ö‡§ø‡§§‡•ç‡§∞ ‡§¨‡§®‡§æ ‡§∞‡§π‡§æ ‡§π‡•à..."):
                try:
                    # ‡§Ø‡§π‡§æ‡§Å ‡§π‡§Æ ‡§∏‡•Ä‡§ß‡•á Gemini 3 Flash ‡§ï‡•á Nano Banana 2 ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§ï‡•â‡§≤ ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á
                    model = genai.GenerativeModel('gemini-3-flash') 
                    # ‡§á‡§Æ‡•á‡§ú ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡§®‡•á ‡§ï‡§æ ‡§á‡§Ç‡§ü‡§∞‡§®‡§≤ ‡§ï‡§Æ‡§æ‡§Ç‡§°
                    final_response = f"‡§Æ‡•à‡§®‡•á ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è '{prompt}' ‡§ï‡•Ä ‡§è‡§ï ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§¶‡•Ä ‡§π‡•à‡•§"
                    active_brain = "Nano-Banana-2"
                    
                    # ‡§®‡•ã‡§ü: ‡§á‡§Æ‡•á‡§ú ‡§∏‡•Ä‡§ß‡•á ‡§ö‡•à‡§ü ‡§Æ‡•á‡§Ç ‡§¶‡§ø‡§ñ‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§Æ ‡§ú‡•á‡§Æ‡§ø‡§®‡•Ä ‡§ï‡§æ ‡§∞‡§ø‡§∏‡•ç‡§™‡•â‡§®‡•ç‡§∏ ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á
                    response = model.generate_content(prompt)
                    st.markdown(response.text)
                except Exception as e:
                    st.error(f"‡§á‡§Æ‡•á‡§ú ‡§¨‡§®‡§æ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§¶‡§ø‡§ï‡•ç‡§ï‡§§ ‡§Ü‡§à: {e}")
                    final_response = "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•à‡§Ç ‡§Ö‡§≠‡•Ä ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡§æ ‡§™‡§æ‡§Ø‡§æ‡•§"

            # C. ‡§´‡•á‡§≤‡§ì‡§µ‡§∞ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ (‡§Ü‡§™‡§ï‡§æ ‡§Ö‡§∏‡§≤‡•Ä 30 ‡§¶‡§ø‡§Æ‡§æ‡§ó‡•ã‡§Ç ‡§µ‡§æ‡§≤‡§æ ‡§≤‡•â‡§ú‡§ø‡§ï)
            else:
                with st.spinner("Thinking through multiple brains..."):
                    for model_name in BRAINS:
                        try:
                            llm = ChatGroq(groq_api_key=GROQ_KEY, model_name=model_name, timeout=15)
                            instruction = f"{SYSTEM_PROMPT} {search_data}"
                            response = llm.invoke([SystemMessage(content=instruction)] + st.session_state.chat_history)
                            final_response = response.content
                            active_brain = model_name
                            break 
                        except: continue

            if final_response:
                response_placeholder.markdown(final_response)
                st.caption(f"‚ö° Active Brain: {active_brain}")
                if st.session_state.get("voice_on"): speak_text(final_response)
                st.session_state.chat_history.append(AIMessage(content=final_response))
            else:
                st.error("All brains are exhausted. Please check your API Keys!")

# 8. Sidebar Features
with st.sidebar:
    st.header("Rajaram AI Control")
    st.info("üìç Bareilly, India | Class 10")
    st.divider()
    st.session_state.voice_on = st.toggle("Live Voice Mode", value=False)
    # ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§™‡§∞ ‡§´‡•á‡§∏-‡§ü‡•Ç-‡§´‡•á‡§∏ ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂
    st.warning("üé§ ‡§≤‡§æ‡§á‡§µ ‡§´‡•á‡§∏-‡§ü‡•Ç-‡§´‡•á‡§∏ ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§ê‡§™ ‡§™‡§∞ 'Gemini Live' ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§")
    if st.button("Clear Memory"):
        st.session_state.chat_history = [SystemMessage(content=SYSTEM_PROMPT)]
        st.rerun()
