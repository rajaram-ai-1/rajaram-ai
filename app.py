import streamlit as st
from streamlit_mic_recorder import mic_recorder
from groq import Groq
import speech_recognition as rgn
import io
import base64
from PIL import Image

# --- 1. рдкреЗрдЬ рд╕реЗрдЯрд┐рдВрдЧ рдФрд░ рд╕реБрд░рдХреНрд╖рд╛ рдХрд╡рдЪ ---
st.set_page_config(page_title="Rajaram AI", page_icon="ЁЯСС", layout="centered")

# CSS: рдбрд┐рдЬрд╝рд╛рдЗрди рдФрд░ рдЪреИрдЯрдмреЙрдХреНрд╕ рдХреЛ рдиреАрдЪреЗ рд╕реЗрдЯ рдХрд░рдирд╛
st.markdown("""
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .stAppDeployButton {display:none !important;}
    
    /* рдЪреИрдЯ рдПрд░рд┐рдпрд╛ рдореЗрдВ рдиреАрдЪреЗ рдЬрдЧрд╣ рдЫреЛреЬрдирд╛ */
    .main { margin-bottom: 130px; }
    
    /* рдЗрдирдкреБрдЯ рдХрдВрдЯреЗрдирд░ рдХреЛ рд╕рдмрд╕реЗ рдиреАрдЪреЗ рдлрд┐рдХреНрд╕ рдХрд░рдирд╛ */
    div[data-testid="stVerticalBlock"] > div:last-child {
        position: fixed;
        bottom: 25px;
        left: 0;
        width: 100%;
        background-color: #0E1117;
        padding: 15px 5% 25px 5%;
        z-index: 1000;
        border-top: 2px solid #333;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. рдорд╣рд╛-рд╢рдХреНрддрд┐рдпреЛрдВ рдХреА рдлреМрдЬ (25+ Models List) ---
# рдпрд╣рд╛рдБ рд╣рдордиреЗ рдирдП рдФрд░ рдЪрд╛рд▓реВ рдореЙрдбрд▓реНрд╕ рдХреЛ рдкреНрд░рд╛рдердорд┐рдХрддрд╛ рджреА рд╣реИ
groq_army = [
    "llama-3.3-70b-versatile",   # рд╕реЗрдирд╛рдкрддрд┐ (рд╕рдмрд╕реЗ рддрд╛рдХрддрд╡рд░)
    "llama-3.1-70b-versatile",   # рдорд╣рд╛-рдЬреНрдЮрд╛рдиреА
    "llama-3.1-8b-instant",      # рдЪреБрд▓рдмреБрд▓рд╛ рдФрд░ рддреЗреЫ
    "mixtral-8x7b-32768",        # рд╡рд┐рджреЗрд╢реА рд╢рдХреНрддрд┐
    "gemma2-9b-it",              # рдЧреВрдЧрд▓ рдХрд╛ рджрд┐рдорд╛рдЧ
    "llama-3.2-11b-vision-preview", 
    "llama-3.2-3b-preview",
    "llama-3.2-1b-preview",
    "llama-guard-3-8b"           # рд░рдХреНрд╖рдХ рдореЙрдбрд▓
]

# --- 3. рд╕реНрдорд╛рд░реНрдЯ рджрд┐рдорд╛рдЧ рдЪреБрдирдиреЗ рд╡рд╛рд▓рд╛ рдЗрдВрдЬрди ---
def select_best_brain(messages_history):
    user_input = messages_history[-1]["content"].lower()
    # рдкреЭрд╛рдИ рд╡рд╛рд▓реЗ рдХреАрд╡рд░реНрдбреНрд╕
    if any(word in user_input for word in ["padhai", "exam", "science", "maths", "class", "subject", "рддреИрдпрд╛рд░реА"]):
        return "llama-3.3-70b-versatile", "ЁЯУЦ рдкреЭрд╛рдИ рд╡рд╛рд▓рд╛ рджрд┐рдорд╛рдЧ (70B)"
    # рдордЬрд╛рдХ рдорд╕реНрддреА рд╡рд╛рд▓реЗ рдХреАрд╡рд░реНрдбреНрд╕
    elif any(word in user_input for word in ["majak", "joke", "funny", "hi", "kaise ho", "рдордЬрд╛рдХ"]):
        return "llama-3.1-8b-instant", "ЁЯШВ рдЪреБрд▓рдмреБрд▓рд╛ рджрд┐рдорд╛рдЧ (8B)"
    else:
        return "llama-3.3-70b-versatile", "ЁЯза рдЬреНрдЮрд╛рдиреА рджрд┐рдорд╛рдЧ"

# --- 4. 'рдЕрдорд░' рд░рд┐рд╕реНрдкреЙрдиреНрд╕ рдлрдВрдХреНрд╢рди (Failover Logic) ---
def get_response(messages_history):
    best_brain, display_name = select_best_brain(messages_history)
    
    # рдЕрдЧрд░ рдЪреБрдирд╛ рд╣реБрдЖ рдореЙрдбрд▓ рдлреЗрд▓ рд╣реЛ, рддреЛ рдмрд╛рдХреА рдлреМрдЬ рдХрд╛рдо рдХрд░реЗрдЧреА
    models_to_try = [best_brain] + [m for m in groq_army if m != best_brain]
    
    for model_name in models_to_try:
        try:
            client = Groq(api_key=st.secrets["GROQ_API_KEY"])
            completion = client.chat.completions.create(
                model=model_name,
                messages=messages_history,
                temperature=0.7,
                max_tokens=2048,
            )
            return completion.choices[0].message.content, f"{model_name}"
        except Exception as e:
            # рдЕрдЧрд░ рдореЙрдбрд▓ рдЦрд░рд╛рдм рд╣реИ, рддреЛ рдЕрдЧрд▓реЗ рдкрд░ рд╕реНрд╡рд┐рдЪ рдХрд░реЛ
            continue 
            
    return "рднрд╛рдИ, рдкреВрд░реА рдлреМрдЬ рдердХ рдЧрдИ рд╣реИ! рдХреГрдкрдпрд╛ рдЗрдВрдЯрд░рдиреЗрдЯ рдпрд╛ рдЪрд╛рдмреА рдЪреЗрдХ рдХрд░реЗрдВред", "Error"

# --- 5. рдЖрд╡рд╛реЫ рдХреЛ рд╕рдордЭрдиреЗ рд╡рд╛рд▓рд╛ рдпрдВрддреНрд░ ---
def translate_voice(audio_bytes):
    recognizer = rgn.Recognizer()
    audio_file = io.BytesIO(audio_bytes)
    try:
        with rgn.AudioFile(audio_file) as source:
            audio = recognizer.record(source)
        return recognizer.recognize_google(audio, language='hi-IN')
    except:
        return None

# --- 6. рджрд░рдмрд╛рд░ рдХреА рд╕рдЬрд╛рд╡рдЯ ---
st.markdown("<h1 style='text-align: center;'>ЁЯСС Rajaram AI</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'><b>25+ рдорд╣рд╛-рд╢рдХреНрддрд┐рдпреЛрдВ рдХрд╛ рдХрд╡рдЪ - рдЕрдорд░, рд╕реБрд░рдХреНрд╖рд┐рдд рдФрд░ рддреЗрдЬрд╝</b></p>", unsafe_allow_html=True)
st.markdown("---")

# рдпрд╛рджрджрд╛рд╢реНрдд (Chat History)
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "рддреБрдо 'рд░рд╛рдЬрд╛рд░рд╛рдо AI' рд╣реЛред рддреБрдо рдмрд░реЗрд▓реА рдХреЗ рд░рд╛рдЬрд╛рд░рд╛рдо рднрд╛рдИ (15 рд╕рд╛рд▓, рдХреНрд▓рд╛рд╕ 10) рдХреЗ рд▓рд┐рдП рдХрд╛рдо рдХрд░рддреЗ рд╣реЛред рд╣рдореЗрд╢рд╛ рд╣рд┐рдВрджреА рдореЗрдВ рдмрд╛рдд рдХрд░реЛ рдФрд░ рднрд╛рдИ рдХрд╣рдХрд░ рд╕рдореНрдорд╛рди рджреЛред"}
    ]

# рдкреБрд░рд╛рдиреА рдЪреИрдЯ рд╕реНрдХреНрд░реАрди рдкрд░ рджрд┐рдЦрд╛рдирд╛
for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

# --- 7. рдЗрдирдкреБрдЯ (рдорд╛рдЗрдХ + рдЪреИрдЯрдмреЙрдХреНрд╕) ---
prompt = None
footer_container = st.container()
with footer_container:
    c1, c2 = st.columns([1, 7])
    with c1:
        audio_data = mic_recorder(start_prompt="ЁЯОд", stop_prompt="тЬЕ", key='rajaram_final_mic')
    with c2:
        input_text = st.chat_input("рд░рд╛рдЬрд╛рд░рд╛рдо рднрд╛рдИ рд╕реЗ рдХреБрдЫ рдкреВрдЫреЗрдВ...")

# --- 8. рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рд▓реЙрдЬрд┐рдХ ---
if audio_data:
    voice_text = translate_voice(audio_data['bytes'])
    if voice_text:
        prompt = voice_text
        st.info(f"ЁЯОд рдЖрдкрдиреЗ рдХрд╣рд╛: {voice_text}")
elif input_text:
    prompt = input_text

if prompt:
    # рдпреВрдЬрд░ рдХрд╛ рд╕рдВрджреЗрд╢
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    # AI рдХрд╛ рдЬрд╡рд╛рдм (рдЕрдорд░ рдлреМрдЬ рдХреЗ рд╕рд╛рде)
    with st.chat_message("assistant"):
        with st.spinner("рдлреМрдЬ рдореЛрд░реНрдЪрд╛ рд╕рдВрднрд╛рд▓ рд░рд╣реА рд╣реИ..."):
            ans, model_used = get_response(st.session_state.messages)
            st.toast(f"рд╢рдХреНрддрд┐ рддреИрдирд╛рдд: {model_used}", icon='ЁЯЪА')
            st.write(ans)
            st.caption(f"рд╕рдХреНрд░рд┐рдп рдорд╣рд╛-рд╢рдХреНрддрд┐: {model_used}")
    
    st.session_state.messages.append({"role": "assistant", "content": ans})
    st.rerun()
