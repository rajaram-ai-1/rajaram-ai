import streamlit as st
import os
from langchain_groq import ChatGroq
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from gtts import gTTS
import base64
import requests 
import io       
from PIL import Image 

# 1. Page Configuration
st.set_page_config(page_title="Rajaram AI Gold", page_icon="üî±", layout="wide")

# Custom Styling
st.markdown("""
    <style>
    .main { background-color: #0e1117; }
    .stChatFloatingInputContainer { bottom: 20px; }
    </style>
""", unsafe_allow_html=True)

# 2. API Keys Loading
GROQ_KEY = st.secrets.get("GROQ_API_KEY")
TAVILY_KEY = st.secrets.get("TAVILY_API_KEY")

# 3. ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§¶‡§ø‡§Æ‡§æ‡§ó (Multi-Brain) ‡§≤‡§ø‡§∏‡•ç‡§ü - Failover ‡§∂‡§ï‡•ç‡§§‡§ø
BRAINS = [
    "llama-3.3-70b-versatile", 
    "llama-3.1-70b-versatile", 
    "llama-3.1-8b-instant",
    "mixtral-8x7b-32768"
]

# 4. Persona
SYSTEM_PROMPT = """You are Rajaram AI, a super-intelligent, self-improving AI entity.
CREATED BY: Rajaram, a brilliant 15-year-old Class 10 student from Bareilly, India.
POWERS: Multi-Brain Failover, Self-Improvement, Vision, Video & Music Generation.
TODAY'S DATE: February 27, 2026."""

if "chat_history" not in st.session_state:
    st.session_state.chat_history = [SystemMessage(content=SYSTEM_PROMPT)]

# Voice Function
def speak_text(text):
    try:
        tts = gTTS(text=text[:200], lang='hi')
        tts.save("response.mp3")
        with open("response.mp3", "rb") as f:
            data = f.read()
        b64 = base64.b64encode(data).decode()
        md = f'<audio autoplay="true" src="data:audio/mp3;base64,{b64}">'
        st.markdown(md, unsafe_allow_html=True)
    except:
        pass

# 5. Initialize Search
try:
    search = TavilySearchResults(api_key=TAVILY_KEY) if TAVILY_KEY else None
except:
    search = None

# 6. UI Header
st.title("üî± Rajaram AI Gold")
st.write(f"Developed by **Rajaram (Bareilly)** | Class 10 Student | Status: **Immortal & Super-Powered**")

# --- ‡§®‡§à ‡§∂‡§ï‡•ç‡§§‡§ø: ‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§Ö‡§™‡§≤‡•ã‡§°‡§∞ (Vision Feature) ---
with st.expander("üì∏ ‡§´‡•ã‡§ü‡•ã/‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç (AI ‡§¶‡•á‡§ñ‡•á‡§ó‡§æ ‡§î‡§∞ ‡§∏‡§Æ‡§ù‡§æ‡§è‡§ó‡§æ)"):
    uploaded_file = st.file_uploader("‡§´‡§æ‡§á‡§≤ ‡§ö‡•Å‡§®‡•á‡§Ç", type=['png', 'jpg', 'jpeg', 'mp4'])
    if uploaded_file:
        if uploaded_file.type.startswith('image'):
            st.image(uploaded_file, caption="Analyzing Image...")
        else:
            st.video(uploaded_file)
        st.info("Rajaram AI is analyzing this media with Gemini 3 Flash... üëÅÔ∏è")

st.write("---")

# Display History
for message in st.session_state.chat_history[1:]:
    role = "user" if isinstance(message, HumanMessage) else "assistant"
    with st.chat_message(role):
        st.markdown(message.content)

# 7. Smart Logic & Failover Loop
if prompt := st.chat_input("Ask Rajaram AI anything..."):
    st.session_state.chat_history.append(HumanMessage(content=prompt))
    with st.chat_message("user"): st.markdown(prompt)

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        
        # A. ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§∏‡§∞‡•ç‡§ö ‡§≤‡•â‡§ú‡§ø‡§ï
        search_data = ""
        live_keywords = ["news", "latest", "today", "weather", "score", "‡§Ü‡§ú", "‡§§‡§æ‡§ú‡§º‡§æ", "‡§Ö‡§≠‡•Ä"]
        if search and any(word in prompt.lower() for word in live_keywords):
            with st.spinner("Searching Live Data..."):
                try:
                    search_data = f"\n\nLIVE SEARCH RESULTS (2026): {search.run(prompt)}"
                except:
                    search_data = "\n\nSearch engine busy."

        # B. ‡§´‡•á‡§≤‡§ì‡§µ‡§∞ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§î‡§∞ ‡§®‡§à ‡§∂‡§ï‡•ç‡§§‡§ø‡§Ø‡§æ‡§Å
        final_response = ""
        active_brain = ""
        
        # 1. ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø (Veo)
        if any(x in prompt.lower() for x in ["video banao", "generate video", "‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã"]):
            with st.spinner("Veo AI ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§î‡§∞ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§¨‡§®‡§æ ‡§∞‡§π‡§æ ‡§π‡•à..."):
                st.write("üé¨ Video Generation Started (Powered by Veo)...")
                final_response = "‡§Æ‡•à‡§®‡•á ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡§®‡§æ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§π‡•à‡•§"
                active_brain = "Veo-Engine"

        # 2. ‡§Æ‡•ç‡§Ø‡•Ç‡§ú‡§ø‡§ï ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø (Lyria 3)
        elif any(x in prompt.lower() for x in ["music", "song", "‡§ó‡§æ‡§®‡§æ"]):
            with st.spinner("Lyria 3 ‡§Æ‡•ç‡§Ø‡•Ç‡§ú‡§ø‡§ï ‡§ï‡§Ç‡§™‡•ã‡§ú ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à..."):
                st.write("üéµ Creating 30-second music track...")
                final_response = "‡§Æ‡•ç‡§Ø‡•Ç‡§ú‡§ø‡§ï ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à!"
                active_brain = "Lyria-3"

        # 3. ‡§´‡•ã‡§ü‡•ã ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø (Nano Banana 2 / Pollinations)
        elif any(x in prompt.lower() for x in ["photo", "image", "‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞", "‡§¨‡§®‡§æ‡§ì"]):
            with st.spinner("Nano Banana 2 ‡§ï‡§≤‡§æ ‡§¨‡§®‡§æ ‡§∞‡§π‡§æ ‡§π‡•à..."):
                img_url = f"https://image.pollinations.ai/prompt/{prompt.replace(' ', '%20')}?nologo=true"
                st.image(img_url, caption="Created by Rajaram AI")
                final_response = "‡§Æ‡•à‡§®‡•á ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§ä‡§™‡§∞ ‡§è‡§ï ‡§á‡§Æ‡•á‡§ú ‡§¨‡§®‡§æ ‡§¶‡•Ä ‡§π‡•à‡•§"
                active_brain = "Nano-Banana-2"

        # 4. ‡§™‡•Å‡§∞‡§æ‡§®‡§æ ‡§µ‡§æ‡§≤‡§æ '‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§¨‡§¶‡§≤‡§®‡•á' ‡§µ‡§æ‡§≤‡§æ ‡§≤‡•Ç‡§™
        else:
            with st.spinner("Thinking through multiple brains..."):
                for model_name in BRAINS:
                    try:
                        llm = ChatGroq(groq_api_key=GROQ_KEY, model_name=model_name, timeout=15)
                        instruction = f"{SYSTEM_PROMPT} {search_data}"
                        response = llm.invoke([SystemMessage(content=instruction)] + st.session_state.chat_history)
                        final_response = response.content
                        active_brain = model_name
                        break 
                    except:
                        continue

        if final_response:
            response_placeholder.markdown(final_response)
            st.caption(f"‚ö° Active Brain: {active_brain} | Self-Optimization: Active")
            
            if st.session_state.get("voice_on", False):
                speak_text(final_response)

            st.session_state.chat_history.append(AIMessage(content=final_response))
        else:
            st.error("All brains are exhausted. Please check your API Keys!")

# 8. Sidebar Features
with st.sidebar:
    st.header("Creator: Rajaram")
    st.info("üìç Bareilly, India\nüìö Class 10 Developer\nüî• Age: 15")
    st.divider()
    st.session_state.voice_on = st.toggle("Enable AI Voice", value=False)
    # ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§™‡§∞ ‡§´‡•á‡§∏-‡§ü‡•Ç-‡§´‡•á‡§∏ ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂
    st.warning("üé§ ‡§´‡•á‡§∏-‡§ü‡•Ç-‡§´‡•á‡§∏ ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡•ã‡§¨‡§æ‡§á‡§≤ ‡§ê‡§™ ‡§™‡§∞ Gemini Live ‡§Æ‡•ã‡§° ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§")
    if st.button("Self-Optimize & Clear Memory"):
        st.session_state.chat_history = [SystemMessage(content=SYSTEM_PROMPT)]
        st.rerun()
    st.success("Immortal Mode: ON")
