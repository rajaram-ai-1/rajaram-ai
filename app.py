import streamlit as st
from groq import Groq
import google.generativeai as genai
from PIL import Image

# --- 1. ‡§ö‡§æ‡§¨‡§ø‡§Ø‡§æ‡§Å (Secrets) ---
try:
    GROQ_K = st.secrets["GROQ_API_KEY"]
    GEMINI_K = st.secrets["GOOGLE_API_KEY"]
    client_groq = Groq(api_key=GROQ_K)
    
    # ‡§ó‡•Ç‡§ó‡§≤ ‡§ï‡•ã ‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§µ‡§∞‡•ç‡§ú‡§® ‡§™‡§∞ ‡§∏‡•á‡§ü ‡§ï‡§∞‡§®‡§æ
    genai.configure(api_key=GEMINI_K)
except Exception as e:
    st.error(f"‡§≠‡§æ‡§à, ‡§ö‡§æ‡§¨‡§ø‡§Ø‡§æ‡§Å ‡§ö‡•á‡§ï ‡§ï‡§∞‡•ã: {e}")
    st.stop()

# --- 2. ‡§¶‡•á‡§ñ‡§®‡•á ‡§î‡§∞ ‡§∏‡•ã‡§ö‡§®‡•á ‡§ï‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ---
def get_ai_response(text, file):
    if file:
        try:
            # ‡§Ø‡§π‡§æ‡§Å 'gemini-1.5-flash-latest' ‡§ï‡§æ ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞‡•á‡§Ç, ‡§Ø‡•á ‡§ï‡§≠‡•Ä ‡§´‡•á‡§≤ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã‡§§‡§æ
            model = genai.GenerativeModel('gemini-1.5-flash-latest')
            img = Image.open(file)
            # ‡§∏‡•ç‡§ü‡•á‡§¨‡§≤ ‡§ú‡§®‡§∞‡•á‡§∂‡§®
            res = model.generate_content([text if text else "‡§á‡§∏‡•á ‡§∏‡§Æ‡§ù‡§æ‡§ì ‡§≠‡§æ‡§à", img])
            return res.text, "Gemini Vision üì∑"
        except Exception as e:
            # ‡§Ö‡§ó‡§∞ ‡§´‡§ø‡§∞ ‡§≠‡•Ä ‡§è‡§∞‡§∞ ‡§Ü‡§è, ‡§§‡•ã ‡§ó‡•ç‡§∞‡•â‡§ï ‡§ï‡•ã ‡§¨‡•à‡§ï‡§Ö‡§™ ‡§Æ‡•á‡§Ç ‡§∞‡§ñ‡•á‡§Ç
            return f"‡§ó‡•Ç‡§ó‡§≤ ‡§≠‡§æ‡§à ‡§Ö‡§≠‡•Ä ‡§≠‡•Ä ‡§®‡§ñ‡§∞‡•á ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§™‡§∞ ‡§π‡§Æ ‡§π‡§æ‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§æ‡§®‡•á‡§Ç‡§ó‡•á! ‡§è‡§∞‡§∞: {str(e)}", "Error"
    else:
        try:
            res = client_groq.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "system", "content": "You are Rajaram AI. A loyal brother. Use Hindi."},
                          {"role": "user", "content": text}]
            )
            return res.choices[0].message.content, "Llama 3.3 ‚ö°"
        except: return "‡§≠‡§æ‡§à, ‡§ó‡•ç‡§∞‡•â‡§ï ‡§Ö‡§≠‡•Ä ‡§¨‡§ø‡§ú‡•Ä ‡§π‡•à‡•§", "None"

# --- 3. ‡§á‡§Ç‡§ü‡§∞‡§´‡§º‡•á‡§∏ (Tools ‡§¨‡§ü‡§® ‡§ö‡•à‡§ü ‡§¨‡•â‡§ï‡•ç‡§∏ ‡§ï‡•á ‡§™‡§æ‡§∏) ---
st.set_page_config(page_title="Rajaram AI", page_icon="üëë")

st.markdown("""
    <style>
    .stApp { background-color: #131314; color: white; }
    .chat-bubble { padding: 15px; border-radius: 15px; border: 1px solid #3c3f43; margin-bottom: 15px; }
    .stChatInput { border-radius: 20px !important; }
    </style>
    """, unsafe_allow_html=True)

st.title("üëë Rajaram AI")

if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡§Æ‡•à‡§∏‡•á‡§ú ‡§¶‡§ø‡§ñ‡§æ‡§®‡§æ
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.write(m["content"])

# --- 4. ‡§ü‡•Ç‡§≤‡•ç‡§∏ ‡§¨‡§æ‡§∞ ---
col1, col2 = st.columns([1, 5])
with col1:
    # ‡§ï‡•à‡§Æ‡§∞‡§æ ‡§Ü‡§á‡§ï‡•â‡§® ‡§µ‡§æ‡§≤‡§æ ‡§õ‡•ã‡§ü‡§æ ‡§Ö‡§™‡§≤‡•ã‡§°‡§∞
    up_file = st.file_uploader("üì∑", type=['png', 'jpg', 'jpeg'], key="camera", label_visibility="collapsed")

with col2:
    prompt = st.chat_input("‡§Ö‡§¨ ‡§™‡•Ç‡§õ‡•ã ‡§≠‡§æ‡§à, ‡§Ö‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§∞‡•Å‡§ï‡•á‡§ó‡§æ...")

if prompt or up_file:
    user_txt = prompt if prompt else "‡§´‡•ã‡§ü‡•ã ‡§¶‡•á‡§ñ‡•ã ‡§≠‡§æ‡§à"
    
    # ‡§°‡•Å‡§™‡•ç‡§≤‡•Ä‡§ï‡•á‡§ü ‡§Æ‡•à‡§∏‡•á‡§ú ‡§∞‡•ã‡§ï‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è
    if not st.session_state.messages or st.session_state.messages[-1]["content"] != user_txt:
        st.session_state.messages.append({"role": "user", "content": user_txt})
        with st.chat_message("user"):
            st.write(user_txt)
            if up_file: st.image(up_file, width=200)

        with st.spinner("‡§∞‡§æ‡§ú‡§æ‡§∞‡§æ‡§Æ AI ‡§ï‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡§æ‡§Æ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•à..."):
            ans, brain = get_ai_response(user_txt, up_file)
            st.session_state.messages.append({"role": "assistant", "content": ans})
            with st.chat_message("assistant"):
                st.write(ans)
                st.caption(f"Active Power: {brain}")
